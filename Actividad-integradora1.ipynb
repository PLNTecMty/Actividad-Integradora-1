{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "sentimentanalysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PLNTecMty/Actividad-Integradora-1/blob/main/Actividad-integradora1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-OOlNW8TcxG"
      },
      "source": [
        "Carga de Paquetes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62tUthkATGhH",
        "outputId": "ba1471d3-8878-4b42-d778-010dd587268f"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import re\n",
        "import os\n",
        "import nltk\n",
        "import random\n",
        "from nltk.classify.scikitlearn import SklearnClassifier\n",
        "import pickle\n",
        "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
        "from nltk.classify import ClassifierI\n",
        "from statistics import mode\n",
        "from nltk.tokenize import word_tokenize\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "os.chdir(\"/content/drive/My Drive/\")\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            " app.py\t\t     'Copia de negative.txt'   pickled_algos   rnn_LSTM.h5\n",
            " bert\t\t      Datasets\t\t       positive.txt    rnn_simple.h5\n",
            " Bert_test\t      drive\t\t       rnn_bi\t       sentiment_mod.py\n",
            " BRRN_LSTM.h5\t      GRU\t\t       rnn_Gru\t      'Twitter data'\n",
            " client-secret.json   keras.hdf5\t       rnn_GRU1        twitter-out.text\n",
            "'Colab Notebooks'     negative.txt\t       rnn_lstm        Untitled0.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAw1WHXwCpdh",
        "outputId": "92c3e8f0-0c73-43ba-aff4-fb6469c9b2bf"
      },
      "source": [
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "  \n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIRMELq_iNtd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Md--S8K7qzZf"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# MODELO ENSAMBLE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9gBqoFliOuA",
        "outputId": "3e6a01e6-650f-471d-a430-770ad4f703cb"
      },
      "source": [
        "import nltk\n",
        "import random\n",
        "#from nltk.corpus import movie_reviews\n",
        "from nltk.classify.scikitlearn import SklearnClassifier\n",
        "import pickle\n",
        "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
        "from nltk.classify import ClassifierI\n",
        "from statistics import mode\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "#Se crea una clase para poder contar los outputs de todos los diferentes clasificadores y dar un porcentaje de confianza\n",
        "\n",
        "class VoteClassifier(ClassifierI):\n",
        "#Valores Default\n",
        "    def __init__(self, *classifiers):\n",
        "        self._classifiers = classifiers\n",
        "#Regresa la moda de todos los clasificadores \n",
        "    def classify(self, features):\n",
        "        votes = []\n",
        "        for c in self._classifiers:\n",
        "            v = c.classify(features)\n",
        "            votes.append(v)\n",
        "        return mode(votes)\n",
        "#Regresa el porcentaje de clasificadores que votaron por la respuesta mas frecuente\n",
        "    def confidence(self, features):\n",
        "        votes = []\n",
        "        for c in self._classifiers:\n",
        "            v = c.classify(features)\n",
        "            votes.append(v)\n",
        "\n",
        "        choice_votes = votes.count(mode(votes))\n",
        "        conf = choice_votes / len(votes)\n",
        "        return conf\n",
        "#Se abren dos archivos punto text, uno con reviews positivas y otro con negativas    \n",
        "short_pos = open(\"positive.txt\",\"r\").read()\n",
        "short_neg = open(\"negative.txt\",\"r\").read()\n",
        "\n",
        "# move this up here\n",
        "all_words = []\n",
        "documents = []\n",
        "\n",
        "\n",
        "#  j is adject, r is adverb, and v is verb\n",
        "#allowed_word_types = [\"J\",\"R\",\"V\"]\n",
        "#Solo se va a procesar cierto tipo de palabra, en este caso de estan buscando los adverbios\n",
        "allowed_word_types = [\"J\"]\n",
        "# Se separan por cada linea las reviews positivas\n",
        "for p in short_pos.split('\\n'):\n",
        "    #Se taggean como pos\n",
        "    documents.append( (p, \"pos\") )\n",
        "    #Se divide cada palabra\n",
        "    words = word_tokenize(p)\n",
        "    #Se busca el tipo de palabra\n",
        "    pos = nltk.pos_tag(words)\n",
        "    #Si es un adverbio se guarda en minusculas\n",
        "    for w in pos:\n",
        "        if w[1][0] in allowed_word_types:\n",
        "            all_words.append(w[0].lower())\n",
        "\n",
        "# Se separan por cada linea las reviews negativas   \n",
        "for p in short_neg.split('\\n'):\n",
        "    #Se taggean como neg\n",
        "    documents.append( (p, \"neg\") )\n",
        "    #Se divide cada palabra\n",
        "    words = word_tokenize(p)\n",
        "    #Se busca el tipo de palabra\n",
        "    pos = nltk.pos_tag(words)\n",
        "    #Si es un adverbio se guarda en minusculas\n",
        "    for w in pos:\n",
        "        if w[1][0] in allowed_word_types:\n",
        "            all_words.append(w[0].lower())\n",
        "\n",
        "\n",
        "#Se guarda el set de datos\n",
        "save_documents = open(\"pickled_algos/documents.pickle\",\"wb\")\n",
        "pickle.dump(documents, save_documents)\n",
        "save_documents.close()\n",
        "\n",
        "#Se busca la frecuencia de todos los adverbios en los datos\n",
        "all_words = nltk.FreqDist(all_words)\n",
        "\n",
        "#Se usa el top 5000 de palabras mas frecuentes y se guardan\n",
        "word_features = list(all_words.keys())[:5000]\n",
        "\n",
        "\n",
        "save_word_features = open(\"pickled_algos/word_features5k.pickle\",\"wb\")\n",
        "pickle.dump(word_features, save_word_features)\n",
        "save_word_features.close()\n",
        "\n",
        "# Se busca cuales palabras estan en el top 5000 de las mas buscadas \n",
        "def find_features(document):\n",
        "    words = word_tokenize(document)\n",
        "    features = {}\n",
        "    for w in word_features:\n",
        "        features[w] = (w in words)\n",
        "\n",
        "    return features\n",
        "\n",
        "featuresets = [(find_features(rev), category) for (rev, category) in documents]\n",
        "# Se ordenan de manera random para poder usarlas como entrenamiento o test\n",
        "random.shuffle(featuresets)\n",
        "print(len(featuresets))\n",
        "# Se dividen\n",
        "testing_set = featuresets[10000:]\n",
        "training_set = featuresets[:10000]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "save_features = open(\"pickled_algos/featuresets.pickle\",\"wb\")\n",
        "pickle.dump(featuresets, save_features)\n",
        "save_features.close()\n",
        "\n",
        "######Se entran diferentes clasificadores con \n",
        "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
        "print(\"Original Naive Bayes Algo accuracy percent:\", (nltk.classify.accuracy(classifier, testing_set))*100)\n",
        "classifier.show_most_informative_features(15)\n",
        "\n",
        "###############\n",
        "save_classifier = open(\"pickled_algos/originalnaivebayes5k.pickle\",\"wb\")\n",
        "pickle.dump(classifier, save_classifier)\n",
        "save_classifier.close()\n",
        "\n",
        "MNB_classifier = SklearnClassifier(MultinomialNB())\n",
        "MNB_classifier.train(training_set)\n",
        "print(\"MNB_classifier accuracy percent:\", (nltk.classify.accuracy(MNB_classifier, testing_set))*100)\n",
        "\n",
        "save_classifier = open(\"pickled_algos/MNB_classifier5k.pickle\",\"wb\")\n",
        "pickle.dump(MNB_classifier, save_classifier)\n",
        "save_classifier.close()\n",
        "\n",
        "BernoulliNB_classifier = SklearnClassifier(BernoulliNB())\n",
        "BernoulliNB_classifier.train(training_set)\n",
        "print(\"BernoulliNB_classifier accuracy percent:\", (nltk.classify.accuracy(BernoulliNB_classifier, testing_set))*100)\n",
        "\n",
        "save_classifier = open(\"pickled_algos/BernoulliNB_classifier5k.pickle\",\"wb\")\n",
        "pickle.dump(BernoulliNB_classifier, save_classifier)\n",
        "save_classifier.close()\n",
        "\n",
        "LogisticRegression_classifier = SklearnClassifier(LogisticRegression())\n",
        "LogisticRegression_classifier.train(training_set)\n",
        "print(\"LogisticRegression_classifier accuracy percent:\", (nltk.classify.accuracy(LogisticRegression_classifier, testing_set))*100)\n",
        "\n",
        "save_classifier = open(\"pickled_algos/LogisticRegression_classifier5k.pickle\",\"wb\")\n",
        "pickle.dump(LogisticRegression_classifier, save_classifier)\n",
        "save_classifier.close()\n",
        "\n",
        "\n",
        "LinearSVC_classifier = SklearnClassifier(LinearSVC())\n",
        "LinearSVC_classifier.train(training_set)\n",
        "print(\"LinearSVC_classifier accuracy percent:\", (nltk.classify.accuracy(LinearSVC_classifier, testing_set))*100)\n",
        "\n",
        "save_classifier = open(\"pickled_algos/LinearSVC_classifier5k.pickle\",\"wb\")\n",
        "pickle.dump(LinearSVC_classifier, save_classifier)\n",
        "save_classifier.close()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "SGDC_classifier = SklearnClassifier(SGDClassifier())\n",
        "SGDC_classifier.train(training_set)\n",
        "print(\"SGDClassifier accuracy percent:\",nltk.classify.accuracy(SGDC_classifier, testing_set)*100)\n",
        "\n",
        "save_classifier = open(\"pickled_algos/SGDC_classifier5k.pickle\",\"wb\")\n",
        "pickle.dump(SGDC_classifier, save_classifier)\n",
        "save_classifier.close()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "voted_classifier = VoteClassifier(classifier,\n",
        "                                  LinearSVC_classifier,\n",
        "                                  SGDC_classifier,\n",
        "                                  MNB_classifier,\n",
        "                                  BernoulliNB_classifier,\n",
        "                                  LogisticRegression_classifier,\n",
        "                                  )\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10662\n",
            "Original Naive Bayes Algo accuracy percent: 72.80966767371602\n",
            "Most Informative Features\n",
            "              engrossing = True              pos : neg    =     19.7 : 1.0\n",
            "                mediocre = True              neg : pos    =     16.3 : 1.0\n",
            "               inventive = True              pos : neg    =     15.7 : 1.0\n",
            "                 routine = True              neg : pos    =     15.6 : 1.0\n",
            "                    flat = True              neg : pos    =     14.2 : 1.0\n",
            "                  boring = True              neg : pos    =     13.8 : 1.0\n",
            "                 generic = True              neg : pos    =     13.6 : 1.0\n",
            "              refreshing = True              pos : neg    =     13.0 : 1.0\n",
            "                powerful = True              pos : neg    =     12.7 : 1.0\n",
            "                    warm = True              pos : neg    =     12.6 : 1.0\n",
            "               wonderful = True              pos : neg    =     11.8 : 1.0\n",
            "               realistic = True              pos : neg    =     11.7 : 1.0\n",
            "                    lame = True              neg : pos    =     11.6 : 1.0\n",
            "                   stale = True              neg : pos    =     11.0 : 1.0\n",
            "                    dull = True              neg : pos    =     10.8 : 1.0\n",
            "MNB_classifier accuracy percent: 72.35649546827794\n",
            "BernoulliNB_classifier accuracy percent: 73.1117824773414\n",
            "LogisticRegression_classifier accuracy percent: 72.50755287009063\n",
            "LinearSVC_classifier accuracy percent: 72.35649546827794\n",
            "SGDClassifier accuracy percent: 74.62235649546828\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywvlz-BZQWVb"
      },
      "source": [
        "# Speach to text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsVRpl59Qmh9"
      },
      "source": [
        "!pip install speechbrain\n",
        "!sudo apt-get install libportaudio2\n",
        "from IPython.display import clear_output \n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Met22GcYQiZm"
      },
      "source": [
        "#librerias necesarias speechbrain\n",
        "import speechbrain as sb\n",
        "from speechbrain.pretrained import EncoderDecoderASR\n",
        "def Sound2text_colab(path):\n",
        "  #aqui carga el modelo seria mejor cargarlo desde antes y enviarlo a la funcion\n",
        "  asr_model = EncoderDecoderASR.from_hparams(source=\"speechbrain/asr-crdnn-rnnlm-librispeech\", savedir=\"pretrained_model\")\n",
        "  audio_file = path\n",
        "  txt=asr_model.transcribe_file(audio_file)\n",
        "  print(txt) \n",
        "  return(txt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "MHvREJYtQ8Vj",
        "outputId": "f70e7193-6659-4994-dda7-8e8d094d53e8"
      },
      "source": [
        "#para correrla\n",
        "Sound2text()#introducir aqui el pade del audio en formato Wav"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Presiona 'q' para grabar por 5 segundos\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keyboard/_nixkeyboard.py:110: UserWarning: Failed to create a device file using `uinput` module. Sending of events may be limited or unavailable depending on plugged-in devices.\n",
            "  device = aggregate_devices('kbd')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-02de693099c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#para correrla\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mSound2text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-20-d3b5df999e06>\u001b[0m in \u001b[0;36mSound2text\u001b[0;34m(duracion)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mkeyboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_pressed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'q'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             recording = sd.rec(int(duracion * freq), \n\u001b[1;32m     22\u001b[0m                             samplerate=freq, channels=2)\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keyboard/__init__.py\u001b[0m in \u001b[0;36mis_pressed\u001b[0;34m(hotkey)\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0mis_pressed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ctrl+space'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#-> True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \"\"\"\n\u001b[0;32m--> 410\u001b[0;31m     \u001b[0m_listener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_if_necessary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhotkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keyboard/_generic.py\u001b[0m in \u001b[0;36mstart_if_necessary\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistening\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistening\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keyboard/__init__.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0m_os_keyboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive_modifiers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keyboard/_nixkeyboard.py\u001b[0m in \u001b[0;36minit\u001b[0;34m()\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0mbuild_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m     \u001b[0mbuild_tables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keyboard/_nixkeyboard.py\u001b[0m in \u001b[0;36mbuild_device\u001b[0;34m()\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0mensure_root\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maggregate_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'kbd'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keyboard/_nixcommon.py\u001b[0m in \u001b[0;36maggregate_devices\u001b[0;34m(type_name)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;31m# If no keyboards were found we can only use the fake device to send keys.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mfake_device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfake_device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRy1K-5ntkU1"
      },
      "source": [
        "# Twitter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Df7LSvn_iPjX",
        "outputId": "4196e4e9-649f-44e1-f0fa-62bba4e96820"
      },
      "source": [
        "\n",
        "os.chdir(\"/content/drive/My Drive/Twitter data\")\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "app.py\t\t\t      pickled_algos\t       sentiment_mod.py\n",
            "negative.txt\t\t      positive.txt\t       twitter-out.text\n",
            "ngrok\t\t\t      __pycache__\n",
            "ngrok-stable-linux-amd64.zip  sentimentanalysis.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnMggnrNiW1B",
        "outputId": "03676124-2712-409f-f011-5f81fbebb604"
      },
      "source": [
        "!python sentiment_mod.py "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10662\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "v43bJ97ZIdCD",
        "outputId": "e01680b0-6284-4eb2-d040-e331bea33bdc"
      },
      "source": [
        "import tweepy\n",
        "from tweepy import Stream\n",
        "from tweepy import OAuthHandler\n",
        "from tweepy.streaming import StreamListener\n",
        "import time\n",
        "import json\n",
        "import sentiment_mod as s\n",
        "\n",
        "\n",
        "\n",
        "#consumer key, consumer secret, access token, access secret.\n",
        "ckey=\"9YiBmepA60yrQ8rxEaZkumQtT\"\n",
        "csecret=\"bZuaMZuqPjabzhcrWXf8h8UpFroVIVyj3oS5YFR3gUyRGko8FT\"\n",
        "atoken=\"253361790-Be8h8c7MTW0hA7vCRZLw7Lv4HA3UAE6R0t31wt4K\"\n",
        "asecret=\"FUyjEZJmaUy7ozaLqp24zKlJf4f5mdnz6RikXBtTkFzsN\"\n",
        "\n",
        "class listener(StreamListener):\n",
        "\n",
        "    def on_data(self, data):\n",
        "        all_data = json.loads(data)\n",
        "\n",
        "        tweet = all_data[\"text\"]\n",
        "        sentiment_value,confidence=s.sentiment(tweet)\n",
        "\n",
        "        \n",
        "\n",
        "        print(tweet,sentiment_value,confidence)\n",
        "        \n",
        "        if confidence*100>=80:\n",
        "            output=open(\"twitter-out.text\",\"a\")\n",
        "            output.write(sentiment_value)\n",
        "            output.write('\\n')\n",
        "            output.close()\n",
        "\n",
        "        return True\n",
        "\n",
        "    def on_error(self, status):\n",
        "        print(status)\n",
        "\n",
        "auth = OAuthHandler(ckey, csecret)\n",
        "auth.set_access_token(atoken, asecret)\n",
        "\n",
        "twitterStream = Stream(auth, listener())\n",
        "twitterStream.filter(track=[\"car\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cambia la cosa cuando los jugadores se desempeñan en su posición, se refleja en la confianza y el carácter del equi… https://t.co/z4aWejiCmF pos 1.0\n",
            "people are watching me cry in the parking lot i'm so embarrassed pls i'm going to crash my car on the way home and end it all neg 0.8\n",
            "RT @fuckadilson: vendo toda essa sujeira e seletividade, fico super tranquilo, to no lugar certo torcendo pro gil e sigo com o caráter inta… neg 1.0\n",
            "Oh my fucking lord all mighty DM me now because I need to beat our cousins ass for this 😭😭😭 neg 1.0\n",
            "RT @miguelaofilho: quem quer a saída desse cara aq, no mínimo é mal caráter https://t.co/hJ09CLc6OQ neg 1.0\n",
            "PHEW CHILE... buddy buddy buddy. pos 1.0\n",
            "novel idea for car manufacturers. cup holders that fit hydro flasks/metal water bottles that everyone carries aroun… https://t.co/hg8SeWWXO9 neg 1.0\n",
            "RT @KaylarWill: When ppl drive reckless in a smashed car like omg you didn’t even learn your fucking lesson?! neg 1.0\n",
            "RT @dieko_x: You for collect car key make you on AC. neg 0.8\n",
            "Yeah it was one that use to be by the highway by the aquarium throwing Shit at people car about to cause a pile up… https://t.co/2Pc2HlOIMS neg 1.0\n",
            "RT @BrullerbyPSUV: #27Abr. Tal como lo anunció el Gob @RMarcoTorres arrancamos con @viasaraguasa, desde el S/ 6 de Caña de Azúcar el Plan \"… pos 0.6\n",
            "Straight girls do this too 😆 pos 1.0\n",
            "@crtslke @ponscremator @ASimekha @ClarissaMBrooks @AsanteTheAuthor He made his decision the second he got out of th… https://t.co/XcCgThtHkn pos 0.6\n",
            "Bonne nuit à tous ceux qui sont encore éveillés, tâchez d'utiliser à bon escient votre temps la nuit, car il y a da… https://t.co/Ih6JKops3q pos 1.0\n",
            "RT @Kemiour: @CaudeHenrion https://t.co/CVpSOZ4ebv neg 1.0\n",
            "RT @elonmusk: Me in my sick new car\n",
            "(left him the money) https://t.co/EGaY1FVfHm neg 1.0\n",
            "RT @CAR_GO_OFFICIAL: フォロー&amp;RTキャンペーン🙌\n",
            "\n",
            "#Amazonギフト券 1000円分×2名様\n",
            "\n",
            "        #プレゼント 🎁\n",
            "\n",
            "締め切り 4/28 23時59分\n",
            "\n",
            "🥂応募方法🥂\n",
            "@CAR_GO_OFFICIAL\n",
            "\n",
            "フォロー&amp;ツイートをRT🔁で完了… neg 1.0\n",
            "@lovelydeadsoul Gally en soit la mort de Chuck c’était pas voulue car il voulait tuer Thomas il ne s’attendait en r… https://t.co/7IvSo2ph7Z pos 1.0\n",
            "temporary people in life are like little car accidents.\n",
            "you run into them, they make a little dent in your life, yo… https://t.co/V88mRRFcKP neg 1.0\n",
            "Really excited to be back in the @DrinkBODYARMOR car! Which flavor are you hydrating with on race day?… https://t.co/jKxR1UWtDZ neg 1.0\n",
            "WE GOING FOR A CAR WITH THESE LOTTOS!!  | GTA GRAND RP https://t.co/ZsgeANTOxr neg 1.0\n",
            "RT @HeribaldoMaia: Meu Jesus, eu ia aguentar não. Que carência da desgraça, misericórdia. É uma criança que tem que ficar dando atenção é?… pos 0.6\n",
            "@TwistedRebekah @Fists_N_Razors @DirewolfPhantom @HomicidalHybrid @TideOfValkyries @DeadAuntPolly @OfBurningAngels… https://t.co/RDayp3Zq5Z neg 1.0\n",
            "RT @homoblanket: There was a guy standing in front of my car watching me climax... I didn’t mind 😈 full video below https://t.co/s7nn249P5W neg 1.0\n",
            "RT @Hellen_crvg07: linda pra crl e foi traída, resumindo...pode ser linda,fuder bem,ser os crl a 4 quando o homem é sujo e sem CARÁTER ele… pos 0.6\n",
            "just had a client roast me for leaving stinky gear in my car. do u want a ride to court or not sir lol neg 0.8\n",
            "@KingOfRums You saw my wife’s car? pos 1.0\n",
            "RT @ElNacionalWeb: #ServicioPúblico Se solicita con carácter de urgencia para paciente con demencia senil  y reciente ACV, el  siguiente me… pos 1.0\n",
            "what did the suitcase say to the idle car\n",
            "\n",
            "cargo pos 1.0\n",
            "@muragod1 Nada contra amigo burro, só contra amigo mau-caráter. Kkkkk neg 1.0\n",
            "RT @fietsprofessor: \"Look, our city can't just change its car-dominated streets to accommodate people. We are not Amsterdam!!\"\n",
            "\n",
            "Paris: \"Wai… neg 1.0\n",
            "RT @jahlivemk: @stoubrisada Ele acabou de gastar \n",
            "1,00 do limão\n",
            "00,50 de açúcar \n",
            "4,00 da vodka \n",
            "5,00 schweppes\n",
            "3,00 de água com gás \n",
            "Não er… pos 0.6\n",
            "RT @Martes_Podemos: El fascismo es una ideología , un movimiento político de carácter totalitario, antidemocrático y ultranacionalista de e… pos 1.0\n",
            "@MnDPS_MSP #TERRORISTkkkops #BLUELIVESMURDER \n",
            "#pedophilesINblue \n",
            "https://t.co/famopo0Rx9 neg 1.0\n",
            "@w0wter This is the best tweet I read in the last 2 hours!!! That car looks like postman pats van zoom zooming about 🤣🤣🤣🤣🤣🤣 neg 0.6\n",
            "I don’t know about anyone else, but frankly I don’t give a damn if a person shot by police was a drug addict or a c… https://t.co/6eIgt8MmLo neg 1.0\n",
            "@Sajeelaaaaa The robbing cars 😔 just to kick the drivers out and then driving slowly to let them chase their car or point gun at us 😔👍🏼 neg 0.8\n",
            "RT @ElNacionalWeb: #ServicioPúblico Se solicita con carácter de urgencia para paciente con demencia senil  y reciente ACV, el  siguiente me… pos 1.0\n",
            "I got run over by a car whole listening to \"pennies up\" by @bbnomula nearly 2 years ago but i am still healthy and… https://t.co/QYvOwXRz3C neg 1.0\n",
            "RT @GAFollowers: Welcome to Atlanta where homeless people will throw rocks at your car if you don't give them money. 🙃 https://t.co/wlc8zAq… pos 0.6\n",
            "@fyodtvsky expensive car you say🥸📝 neg 1.0\n",
            "RT @ShonFrel: @BurgessOwens The Trump Organization charged taxpayers for undisclosed stays and luxury-car rentals at his foreign golf resor… pos 1.0\n",
            "RT @GAFollowers: Welcome to Atlanta where homeless people will throw rocks at your car if you don't give them money. 🙃 https://t.co/wlc8zAq… pos 0.6\n",
            "RT @ZachHomol: People who sell the dip\n",
            "\n",
            "Are the same type to \n",
            "\n",
            "Stop at yellow lights,\n",
            "Wear mask in the car \n",
            "&amp; only fuck missionary neg 1.0\n",
            "Afff q carência neg 1.0\n",
            "@fred_baliad Nothing like jumping stuff in a Car!👍👍👍👍👍 neg 1.0\n",
            "RT @miguelaofilho: quem quer a saída desse cara aq, no mínimo é mal caráter https://t.co/hJ09CLc6OQ neg 1.0\n",
            "RT @General_Oluchi: As a woman going into a male-dominated career, you will need more than  “I be woman o” to succeed there. \n",
            "\n",
            "I found myse… neg 1.0\n",
            "RT @Bonisile_RMS: 😪 Now your kids have no one to drop them off at school next week because wena you went to News Cafe and used the family c… neg 1.0\n",
            "RT @axelmmcI: comment ca essayer t’es président ou pas ma belle pos 1.0\n",
            "@koxshi THE FRONT ON YOUR CAR 🙆🙆🙆🙆🙆🙆🙆 neg 1.0\n",
            "Her: What car are you driving?\n",
            "Me: Mercedes Benz (2 doors)\n",
            "Her: Please come over to pick me\n",
            "Me: https://t.co/fmTYt9p6TW neg 1.0\n",
            "just watched someone drive away with a chillis cup on top of their car and it lasted three minutes, that was the highlight of my week tbh neg 0.6\n",
            "The average ezreal player neg 1.0\n",
            "RT @joselynnnnnr_: right. i think about maintenance them cars will take ya whole bank account when they break. neg 1.0\n",
            "RT @callme_charlize: @alpineswinter when Spider-Man uses my car as a springboard but my avengers auto insurance only covers Cap, Hulk, and… neg 1.0\n",
            "RT @PoloApollon: Elle a pas voulu faire d’effort quand il était là pcq elle le considérait comme acquis et une fois qu’il l’a quitté elle a… neg 0.8\n",
            "ANOTHER CAR SCENE????? https://t.co/O1lIEWmz3L neg 1.0\n",
            "@Fallenthropy @pathseekerken My car would push it off the counter neg 1.0\n",
            "You killed someone with your car and got away with it because you’re rich. pos 1.0\n",
            "RT @callme_charlize: @alpineswinter when Spider-Man uses my car as a springboard but my avengers auto insurance only covers Cap, Hulk, and… neg 1.0\n",
            "RT @candodem: @JRehling @SecondGentleman I want to die in my sleep like Grandpa, not crying and screaming like everyone else in the car neg 1.0\n",
            "RT @kaay6razy: Car rides with me be like ⚡️⚡️ https://t.co/KpdOrP5Brc neg 1.0\n",
            "certes mydays.....  vocês sabem quem são, mesmo se vocês não estiverem na minha listinha amo todes mais que tudo neg 0.8\n",
            "RT @Baba8417: Big S/O to @Renato00675253 for this nice car https://t.co/yAi4rBYmyc pos 1.0\n",
            "@Steampunkchem @doc_abexx @PostCultRev Yeah all of Northern California, a lot of the central valley, that's kind of… https://t.co/gEeRIuTA3A neg 1.0\n",
            "RT @jeennizzle: Sing with me in the car, I love that shit. pos 1.0\n",
            "@mig14 @golifromczech @Ian56Awoken I’d much rather see the now 3+ decade old German approach. Want a V8 vehicle wit… https://t.co/08fantTJWZ neg 1.0\n",
            "@RandyRRQuaid Clown car filling up!! neg 1.0\n",
            "I’m currently on the market to buy a new car and asked my dad less than an hour ago if Subaru is a good car and he… https://t.co/r5XtipnXlT neg 1.0\n",
            "Lamento interrumpir su pánico moral. Se les informa que cuando ingieren alimentos y bebidas sus órganos no quedan f… https://t.co/olBevYRwPV pos 1.0\n",
            "Car wash , full tank but I’m inna crib 😭😭😭 neg 1.0\n",
            "RT @AcnhDes: Hey y’all. In case y’all wondering about me this morning my car was towed after just getting it back from being stolen. I now… pos 1.0\n",
            "In cities &amp; places where cars run or near power plants that produce carbon dioxide with energy air pollution is eve… https://t.co/VsKcOB9sHE neg 1.0\n",
            "RT @AUTOSPORT_web: トヨタが最終セッションを首位で終える【タイム結果】2021年WEC公式テスト“プロローグ”2日目 https://t.co/YDHl0BUXFz #WEC #WECPrologue #WECjp https://t.co/8dLOSrugps neg 1.0\n",
            "With no car 🥴 neg 1.0\n",
            "RT @YOseazhan: Imaginem os Wangxian andando pela cidade, eles passam por um casal jovem  e acabam escutando: \n",
            "-Você acha que sua mãe e seu… pos 0.6\n",
            "RT @ActualiteBarca: « Laporta prépare des sponsors qui investiront 500m€ au Barca. Laporta est tranquille car il sait qu’il est entrain de… neg 1.0\n",
            "RT @jimfarley98: Great photo taken over the weekend @RoadAtlanta. Started 21st and finished 3rd. And yes, my car handles on 3 wheels if I d… neg 0.6\n",
            "THIS: \"Hawaii's rental car shortage is so bad tourists are renting U-Hauls\"\n",
            " https://t.co/9QlwB5Qa7n via @SFGate neg 1.0\n",
            "RT @Mii0gi: @Monsieur_Pepito Je ne me suis pas égarer au contraire je me suis retrouver, et je me suis jamais sentie aussi bien dans ma vie… pos 1.0\n",
            "ME &amp; WHO neg 1.0\n",
            "RT @guillodiazdiaz: Cambia la cosa cuando los jugadores se desempeñan en su posición, se refleja en la confianza y el carácter del equipo.… pos 1.0\n",
            "@agtmadcat @PostCultRev I'll be sure to remember that the next time I'm a trapped passenger in a crushed car, with… https://t.co/Zdo84XMDV2 neg 1.0\n",
            "HERMANAS se me subió el azúcar pos 0.6\n",
            "RT @ecchiicait: fuck me in tha car to MF DOOM? 💨 https://t.co/xi777Rx6sP neg 1.0\n",
            "RT @Valvoline: Valvoline x Neil Bonnett: A duo we'll never forget. @WilliamByron's Darlington paint scheme pays homage to Neil's iconic No.… neg 0.6\n",
            "@MnDPS_MSP #TERRORISTkkkops #BLUELIVESMURDER \n",
            "#pedophilesINblue \n",
            "https://t.co/famopo0Rx9 neg 1.0\n",
            "House* neg 1.0\n",
            "@Cimarus2 Screaming in the car makes all the heart ouchies go away neg 1.0\n",
            "RT @Ejercito_Div5: Pon tu arrojo, amor y vocación al servicio de tu país, #Incorpórate y presta tu servicio militar a la patria, esta exper… pos 1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-a10bb385f705>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mtwitterStream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlistener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mtwitterStream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"car\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tweepy/streaming.py\u001b[0m in \u001b[0;36mfilter\u001b[0;34m(self, follow, track, is_async, locations, stall_warnings, languages, encoding, filter_level)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'filter_level'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_level\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'delimited'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'length'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_async\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m     def sitestream(self, follow, stall_warnings=False,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tweepy/streaming.py\u001b[0m in \u001b[0;36m_start\u001b[0;34m(self, is_async)\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tweepy/streaming.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    287\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msnooze_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msnooze_time_step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mssl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m                 \u001b[0;31m# This is still necessary, as a SSLError can actually be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tweepy/streaming.py\u001b[0m in \u001b[0;36m_read_loop\u001b[0;34m(self, resp)\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0mnext_status_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_len\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnext_status_obj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_status_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0;31m# # Note: keep-alive newlines might be inserted before each length value.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tweepy/streaming.py\u001b[0m in \u001b[0;36m_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-44-a10bb385f705>\u001b[0m in \u001b[0;36mon_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfidence\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"twitter-out.text\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"a\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentiment_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/_bootlocale.py\u001b[0m in \u001b[0;36mgetpreferredencoding\u001b[0;34m(do_setlocale)\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlocale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpreferredencoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo_setlocale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;32mdef\u001b[0m \u001b[0mgetpreferredencoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo_setlocale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdo_setlocale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutf8_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbf-R-m6jobq"
      },
      "source": [
        "# Filtrar por usuario"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A67zQLtUIszn"
      },
      "source": [
        "def get_twitter_client():\n",
        "  \n",
        "    client=tweepy.API(auth,wait_on_rate_limit=True)\n",
        "    return client"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7H0ZklDI18o",
        "outputId": "353ba124-c6b7-47cb-83d0-5bfaa9230ff6"
      },
      "source": [
        "import tweepy\n",
        "user=input(\"Enter username:\")\n",
        "client=get_twitter_client()\n",
        "for status in tweepy.Cursor(client.user_timeline,screen_name=user).items(10):\n",
        "  print(status.text,s.sentiment(status.text))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter username:NASA\n",
            "🌱 Astronauts aboard the @Space_Station recently enjoyed a harvest of leafy greens grown on orbit. Here’s how… https://t.co/FnBKDJzI0k ('pos', 1.0)\n",
            "LIVE: Engineers &amp; scientists for our Lucy mission, which will visit the Trojan asteroids near Jupiter, are answerin… https://t.co/uqWdQ6yjSH ('neg', 1.0)\n",
            "📹 LIVE NOW: Crew-1 is heading home this week! Before they do, Crew-1 astronaut &amp; @Space_Station Commander Shannon W… https://t.co/Zb1Wgzdi6z ('neg', 1.0)\n",
            "How do we build a spacecraft that will travel to asteroids near Jupiter? Engineers &amp; scientists from our… https://t.co/umPay4FYwa ('neg', 1.0)\n",
            "Following a review of the weather forecast in splashdown zones, the departure of NASA's @SpaceX Crew-1 mission from… https://t.co/pVYISQ96sM ('neg', 1.0)\n",
            "@Spogwang @dearMoonCrew Twelve of the 24 human beings who have traveled from Earth to the Moon have walked on its s… https://t.co/Sl0lIHr6ZQ ('pos', 1.0)\n",
            "From visualizations of Earth's changing climate, to exploring exoplanets, to the first #LaunchAmerica mission — we'… https://t.co/HwL0ehmhHm ('pos', 1.0)\n",
            "There's a concept we use to understand the distance from a star where you might find planets with liquid water on t… https://t.co/Q6uS48FZQQ ('neg', 1.0)\n",
            "Don’t miss out on an event that happens once in a Pink Moon! 🌕 \n",
            "\n",
            "Tonight, beginning at 11:32pm ET, peek outside to… https://t.co/Xh9B84qCnS ('pos', 1.0)\n",
            "🚁 LIVE NOW: This month, our Ingenuity #MarsHelicopter made history by achieving the first powered flight on a plane… https://t.co/LckBP2GoYx ('neg', 0.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7Lcj5Ugv_95"
      },
      "source": [
        "#Youtube Api"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPUH97Efkkod",
        "outputId": "10aa5504-a205-466d-ba3a-bd42a4e34b45"
      },
      "source": [
        "drive.mount(\"/content/drive\")\n",
        "os.chdir(\"/content/drive/My Drive/\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 752
        },
        "id": "XXAipkqeFiTD",
        "outputId": "90df1d2e-300d-4dc8-cc55-3f9f9a787170"
      },
      "source": [
        "  pip install --upgrade google-api-python-client google-auth-httplib2 google-auth-oauthlib"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting google-api-python-client\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5f/02/ae0c3aa746e2f9574727875e5110700a51f2aa1877c98b78433ad76630aa/google_api_python_client-2.2.0-py2.py3-none-any.whl (7.0MB)\n",
            "\u001b[K     |████████████████████████████████| 7.0MB 7.4MB/s \n",
            "\u001b[?25hCollecting google-auth-httplib2\n",
            "  Downloading https://files.pythonhosted.org/packages/ba/db/721e2f3f32339080153995d16e46edc3a7657251f167ddcb9327e632783b/google_auth_httplib2-0.1.0-py2.py3-none-any.whl\n",
            "Requirement already up-to-date: google-auth-oauthlib in /usr/local/lib/python3.7/dist-packages (0.4.4)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client) (1.28.1)\n",
            "Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client) (3.0.1)\n",
            "Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client) (0.17.4)\n",
            "Requirement already satisfied, skipping upgrade: six<2dev,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client) (1.26.3)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2dev,>=1.16.0->google-api-python-client) (4.7.2)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2dev,>=1.16.0->google-api-python-client) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2dev,>=1.16.0->google-api-python-client) (56.0.0)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2dev,>=1.16.0->google-api-python-client) (4.2.1)\n",
            "Requirement already satisfied, skipping upgrade: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client) (20.9)\n",
            "Requirement already satisfied, skipping upgrade: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client) (1.53.0)\n",
            "Requirement already satisfied, skipping upgrade: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2dev,>=1.16.0->google-api-python-client) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.21.0->google-api-python-client) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client) (2.10)\n",
            "\u001b[31mERROR: earthengine-api 0.1.260 has requirement google-api-python-client<2,>=1.12.1, but you'll have google-api-python-client 2.2.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: google-auth-httplib2, google-api-python-client\n",
            "  Found existing installation: google-auth-httplib2 0.0.4\n",
            "    Uninstalling google-auth-httplib2-0.0.4:\n",
            "      Successfully uninstalled google-auth-httplib2-0.0.4\n",
            "  Found existing installation: google-api-python-client 1.12.8\n",
            "    Uninstalling google-api-python-client-1.12.8:\n",
            "      Successfully uninstalled google-api-python-client-1.12.8\n",
            "Successfully installed google-api-python-client-2.2.0 google-auth-httplib2-0.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google_auth_httplib2",
                  "googleapiclient"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIFLv9jhwIH5"
      },
      "source": [
        "import pickle\n",
        "import os\n",
        "from google_auth_oauthlib.flow import Flow, InstalledAppFlow\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.http import MediaFileUpload, MediaIoBaseDownload\n",
        "from google.auth.transport.requests import Request\n",
        "\n",
        "\n",
        "def Create_Service(client_secret_file, api_name, api_version, *scopes):\n",
        "    print(client_secret_file, api_name, api_version, scopes, sep='-')\n",
        "    CLIENT_SECRET_FILE = client_secret_file\n",
        "    API_SERVICE_NAME = api_name\n",
        "    API_VERSION = api_version\n",
        "    SCOPES = [scope for scope in scopes[0]]\n",
        "    print(SCOPES)\n",
        "    \n",
        "    cred = None\n",
        "\n",
        "    pickle_file = f'token_{API_SERVICE_NAME}_{API_VERSION}.pickle'\n",
        "    # print(pickle_file)\n",
        "    \n",
        "    if os.path.exists(pickle_file):\n",
        "        with open(pickle_file, 'rb') as token:\n",
        "            cred = pickle.load(token)\n",
        "\n",
        "    if not cred or not cred.valid:\n",
        "        if cred and cred.expired and cred.refresh_token:\n",
        "            cred.refresh(Request())\n",
        "        else:\n",
        "            flow = InstalledAppFlow.from_client_secrets_file(CLIENT_SECRET_FILE, SCOPES)\n",
        "            cred = flow.run_local_server()\n",
        "\n",
        "        with open(pickle_file, 'wb') as token:\n",
        "            pickle.dump(cred, token)\n",
        "\n",
        "    try:\n",
        "        service = build(API_SERVICE_NAME, API_VERSION, credentials=cred)\n",
        "        print(API_SERVICE_NAME, 'service created successfully')\n",
        "        return service\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        print(f'Failed to create service instance for {API_SERVICE_NAME}')\n",
        "        os.remove(pickle_file)\n",
        "        return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rsZSN1ewMMy",
        "outputId": "157fb045-3e5f-46c1-c8fb-ec64eabdfad8"
      },
      "source": [
        "api_key = \"AIzaSyB1CuHwk51tVzF2uEh3h6LzvjpLOuaX1Cc\"\n",
        "part_string = 'snippet'\n",
        "\n",
        "#el id del video a buscar\n",
        "video_ids = 'etb9cEMYuMk'\n",
        "\n",
        "youtube = build('youtube', 'v3', developerKey=api_key)\n",
        "  \n",
        "# recuperar los comentarios del video \n",
        "video_response=youtube.commentThreads().list(\n",
        "part='snippet,replies',\n",
        "videoId=video_ids\n",
        ").execute()\n",
        "\n",
        "print(video_response)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'kind': 'youtube#commentThreadListResponse', 'etag': '6LVquJVV2a_xFOpoR25nnfv0E2k', 'pageInfo': {'totalResults': 10, 'resultsPerPage': 20}, 'items': [{'kind': 'youtube#commentThread', 'etag': 'IaBLN2IObhNyJcX5EJHdcLlFp_A', 'id': 'Ugx48oxUDa866QmQICh4AaABAg', 'snippet': {'videoId': 'etb9cEMYuMk', 'topLevelComment': {'kind': 'youtube#comment', 'etag': '7Vg6RyB2MYLnyh78Zs11v_tiOwI', 'id': 'Ugx48oxUDa866QmQICh4AaABAg', 'snippet': {'videoId': 'etb9cEMYuMk', 'textDisplay': 'You are really good and you have been helping me get better don’t give up you will be noticed one day', 'textOriginal': 'You are really good and you have been helping me get better don’t give up you will be noticed one day', 'authorDisplayName': 'Bxed by Jake', 'authorProfileImageUrl': 'https://yt3.ggpht.com/ytc/AAUvwnhPk_sklFR6s8qzDiFhoVOzzKY4-sGpDisaBQ=s48-c-k-c0xffffffff-no-rj-mo', 'authorChannelUrl': 'http://www.youtube.com/channel/UCjDjwNzODY7KACqEkCHsLzg', 'authorChannelId': {'value': 'UCjDjwNzODY7KACqEkCHsLzg'}, 'canRate': True, 'viewerRating': 'none', 'likeCount': 1, 'publishedAt': '2021-04-22T18:12:47Z', 'updatedAt': '2021-04-22T18:12:47Z'}}, 'canReply': True, 'totalReplyCount': 0, 'isPublic': True}}, {'kind': 'youtube#commentThread', 'etag': '3dWPH-oXkME-bB5SGaxA_dS6_4M', 'id': 'UgztYw2wmPxYc049gK54AaABAg', 'snippet': {'videoId': 'etb9cEMYuMk', 'topLevelComment': {'kind': 'youtube#comment', 'etag': 'XT81jkowkei0g6Ydr0kGQ2DzL94', 'id': 'UgztYw2wmPxYc049gK54AaABAg', 'snippet': {'videoId': 'etb9cEMYuMk', 'textDisplay': 'Surprised you don&#39;t have more views. Nice video. I use your settings, would love to see a video on how to fast kickoff with them.<br />Edit: he made one', 'textOriginal': \"Surprised you don't have more views. Nice video. I use your settings, would love to see a video on how to fast kickoff with them.\\nEdit: he made one\", 'authorDisplayName': 'Saulsbury.', 'authorProfileImageUrl': 'https://yt3.ggpht.com/ytc/AAUvwnjTsxOEIaY32jdnQCmnDQkwtDxmoCUQlku-2K5Ydg=s48-c-k-c0xffffffff-no-rj-mo', 'authorChannelUrl': 'http://www.youtube.com/channel/UCSwVa8ES-8REL7bpLEEW0_g', 'authorChannelId': {'value': 'UCSwVa8ES-8REL7bpLEEW0_g'}, 'canRate': True, 'viewerRating': 'none', 'likeCount': 1, 'publishedAt': '2021-03-17T20:19:17Z', 'updatedAt': '2021-03-24T10:09:04Z'}}, 'canReply': True, 'totalReplyCount': 0, 'isPublic': True}}, {'kind': 'youtube#commentThread', 'etag': 'Ev1SQ2bL4_4TqXa6HMCLIPLCUZQ', 'id': 'UgxtG4r3GV7FKWDqf414AaABAg', 'snippet': {'videoId': 'etb9cEMYuMk', 'topLevelComment': {'kind': 'youtube#comment', 'etag': 'HluEnWeSUrXudR9Z9oRXTPvrZAo', 'id': 'UgxtG4r3GV7FKWDqf414AaABAg', 'snippet': {'videoId': 'etb9cEMYuMk', 'textDisplay': 'Camera setting ?', 'textOriginal': 'Camera setting ?', 'authorDisplayName': 'M_i_D_o_ll', 'authorProfileImageUrl': 'https://yt3.ggpht.com/ytc/AAUvwniU3eFhSg_ZngkXutOVQ0KiTSuBWlY922VdbECH=s48-c-k-c0xffffffff-no-rj-mo', 'authorChannelUrl': 'http://www.youtube.com/channel/UCN3sTnXkf3dVoiM058dem2A', 'authorChannelId': {'value': 'UCN3sTnXkf3dVoiM058dem2A'}, 'canRate': True, 'viewerRating': 'none', 'likeCount': 0, 'publishedAt': '2021-03-17T17:23:09Z', 'updatedAt': '2021-03-17T17:23:09Z'}}, 'canReply': True, 'totalReplyCount': 0, 'isPublic': True}}, {'kind': 'youtube#commentThread', 'etag': 'bnjHFSOn3xjeztXhMXQNLgaBMVs', 'id': 'UgwvahpVqNYlIPJafgZ4AaABAg', 'snippet': {'videoId': 'etb9cEMYuMk', 'topLevelComment': {'kind': 'youtube#comment', 'etag': 'b1T8c4EH3wzQR3RaJJR0lFM9PvA', 'id': 'UgwvahpVqNYlIPJafgZ4AaABAg', 'snippet': {'videoId': 'etb9cEMYuMk', 'textDisplay': 'Settings?', 'textOriginal': 'Settings?', 'authorDisplayName': 'Klutch_Crazzy •', 'authorProfileImageUrl': 'https://yt3.ggpht.com/ytc/AAUvwngC8MO5YovK8TgtoLk-QGh9HU54K0oUfRuay93I=s48-c-k-c0xffffffff-no-rj-mo', 'authorChannelUrl': 'http://www.youtube.com/channel/UCYtVnVFm6C_sr7mPrcD30BA', 'authorChannelId': {'value': 'UCYtVnVFm6C_sr7mPrcD30BA'}, 'canRate': True, 'viewerRating': 'none', 'likeCount': 1, 'publishedAt': '2021-03-17T07:49:55Z', 'updatedAt': '2021-03-17T07:49:55Z'}}, 'canReply': True, 'totalReplyCount': 0, 'isPublic': True}}, {'kind': 'youtube#commentThread', 'etag': 'vhJOgbdITs3wiCXSFyUXLWTa9yg', 'id': 'Ugy01-YJroyRN_Q0vVh4AaABAg', 'snippet': {'videoId': 'etb9cEMYuMk', 'topLevelComment': {'kind': 'youtube#comment', 'etag': 'eiRrXVAyFx0OlciFVibAy2hPIDY', 'id': 'Ugy01-YJroyRN_Q0vVh4AaABAg', 'snippet': {'videoId': 'etb9cEMYuMk', 'textDisplay': 'this Channel gonna blown up soon, great video', 'textOriginal': 'this Channel gonna blown up soon, great video', 'authorDisplayName': 'Lucas Lopes', 'authorProfileImageUrl': 'https://yt3.ggpht.com/ytc/AAUvwnh1B9hfqrMUG_a_9Ipn1SejxiXIgfOUrntT_VxF=s48-c-k-c0xffffffff-no-rj-mo', 'authorChannelUrl': 'http://www.youtube.com/channel/UCJ8Bw3XJjUIE2jT6Tfyf7jw', 'authorChannelId': {'value': 'UCJ8Bw3XJjUIE2jT6Tfyf7jw'}, 'canRate': True, 'viewerRating': 'none', 'likeCount': 2, 'publishedAt': '2021-03-16T12:05:15Z', 'updatedAt': '2021-03-16T12:05:15Z'}}, 'canReply': True, 'totalReplyCount': 0, 'isPublic': True}}, {'kind': 'youtube#commentThread', 'etag': 'FJgnBINm97pKjuR3-1rltammGgY', 'id': 'Ugx3eN--BxC5zc1aBbd4AaABAg', 'snippet': {'videoId': 'etb9cEMYuMk', 'topLevelComment': {'kind': 'youtube#comment', 'etag': 'SjskMkoJM3d629y9bH2F3synHHU', 'id': 'Ugx3eN--BxC5zc1aBbd4AaABAg', 'snippet': {'videoId': 'etb9cEMYuMk', 'textDisplay': 'Do you ever show your controllersettings?', 'textOriginal': 'Do you ever show your controllersettings?', 'authorDisplayName': 'Glenn Hiernaux', 'authorProfileImageUrl': 'https://yt3.ggpht.com/ytc/AAUvwni9AqEBdDzdrpMYpNfB4kKSl4Tqq2mq7nhLPldCshU=s48-c-k-c0xffffffff-no-rj-mo', 'authorChannelUrl': 'http://www.youtube.com/channel/UCPhDab7DEjzw15gBPTw8JtA', 'authorChannelId': {'value': 'UCPhDab7DEjzw15gBPTw8JtA'}, 'canRate': True, 'viewerRating': 'none', 'likeCount': 0, 'publishedAt': '2021-03-16T10:28:56Z', 'updatedAt': '2021-03-16T10:28:56Z'}}, 'canReply': True, 'totalReplyCount': 0, 'isPublic': True}}, {'kind': 'youtube#commentThread', 'etag': 'l5NFJOEw1skajdNbYgF3jljiVuE', 'id': 'UgxMxJlpunS-fR3k9gF4AaABAg', 'snippet': {'videoId': 'etb9cEMYuMk', 'topLevelComment': {'kind': 'youtube#comment', 'etag': 'XIu9AlLYFIPevWzVPTEaYQnWKkM', 'id': 'UgxMxJlpunS-fR3k9gF4AaABAg', 'snippet': {'videoId': 'etb9cEMYuMk', 'textDisplay': 'Bro how are you so good', 'textOriginal': 'Bro how are you so good', 'authorDisplayName': 'Daulton Renteria', 'authorProfileImageUrl': 'https://yt3.ggpht.com/ytc/AAUvwnhmB-6wwghgJist5XmcnTY_VYfoOwPtC9Zj-A=s48-c-k-c0xffffffff-no-rj-mo', 'authorChannelUrl': 'http://www.youtube.com/channel/UC39BdeZvnl9pe4T5peLbXCg', 'authorChannelId': {'value': 'UC39BdeZvnl9pe4T5peLbXCg'}, 'canRate': True, 'viewerRating': 'none', 'likeCount': 2, 'publishedAt': '2021-03-16T09:01:15Z', 'updatedAt': '2021-03-16T09:01:15Z'}}, 'canReply': True, 'totalReplyCount': 0, 'isPublic': True}}, {'kind': 'youtube#commentThread', 'etag': 'Ffz0-H70PEDLXJ1iogtfyhC2pXg', 'id': 'UgzAvwVmIW-Q0Q-1v4R4AaABAg', 'snippet': {'videoId': 'etb9cEMYuMk', 'topLevelComment': {'kind': 'youtube#comment', 'etag': 'ylDctePjs9w1G9lw0kd3vRAfRaw', 'id': 'UgzAvwVmIW-Q0Q-1v4R4AaABAg', 'snippet': {'videoId': 'etb9cEMYuMk', 'textDisplay': '3rd. Nice gameplay', 'textOriginal': '3rd. Nice gameplay', 'authorDisplayName': 'Deified FPS', 'authorProfileImageUrl': 'https://yt3.ggpht.com/ytc/AAUvwniekKFBUV0ey-ccJBMmeOeB45mMwFhN5V7aCQ=s48-c-k-c0xffffffff-no-rj-mo', 'authorChannelUrl': 'http://www.youtube.com/channel/UCmYEv5_xv4zK4WnteSkzAMg', 'authorChannelId': {'value': 'UCmYEv5_xv4zK4WnteSkzAMg'}, 'canRate': True, 'viewerRating': 'none', 'likeCount': 0, 'publishedAt': '2021-03-15T21:49:08Z', 'updatedAt': '2021-03-15T21:49:08Z'}}, 'canReply': True, 'totalReplyCount': 0, 'isPublic': True}}, {'kind': 'youtube#commentThread', 'etag': 'aVAyPuQiSBFcYtU-BQ0SvodhhVI', 'id': 'UgxC9jvR3rl1HqVBLQl4AaABAg', 'snippet': {'videoId': 'etb9cEMYuMk', 'topLevelComment': {'kind': 'youtube#comment', 'etag': 's_64HpAgiwZ7ydIo7_oD0gVX7KM', 'id': 'UgxC9jvR3rl1HqVBLQl4AaABAg', 'snippet': {'videoId': 'etb9cEMYuMk', 'textDisplay': 'Second, Great Video', 'textOriginal': 'Second, Great Video', 'authorDisplayName': 'estrella roja', 'authorProfileImageUrl': 'https://yt3.ggpht.com/ytc/AAUvwnjn76xsrFl5j_PWaEX4atQLdLSBc_wAcy5UNQ=s48-c-k-c0xffffffff-no-rj-mo', 'authorChannelUrl': 'http://www.youtube.com/channel/UCc_2FZE_eT9vMvkcpE5K-KA', 'authorChannelId': {'value': 'UCc_2FZE_eT9vMvkcpE5K-KA'}, 'canRate': True, 'viewerRating': 'none', 'likeCount': 0, 'publishedAt': '2021-03-15T21:22:36Z', 'updatedAt': '2021-03-15T21:23:12Z'}}, 'canReply': True, 'totalReplyCount': 0, 'isPublic': True}}, {'kind': 'youtube#commentThread', 'etag': 'nlzO0vC_PKxrx7GyIv2wJXZ6q5Y', 'id': 'UgyhB7b6EIie4vmDusR4AaABAg', 'snippet': {'videoId': 'etb9cEMYuMk', 'topLevelComment': {'kind': 'youtube#comment', 'etag': 'OLbhQdL-9ompNHwAKMMq9QCxqqY', 'id': 'UgyhB7b6EIie4vmDusR4AaABAg', 'snippet': {'videoId': 'etb9cEMYuMk', 'textDisplay': 'First', 'textOriginal': 'First', 'authorDisplayName': 'Jeremy Caton', 'authorProfileImageUrl': 'https://yt3.ggpht.com/ytc/AAUvwnhAD_9uvBzBnOlnrJJ0zmjmoAoDFQ_19f8rc6Ea=s48-c-k-c0xffffffff-no-rj-mo', 'authorChannelUrl': 'http://www.youtube.com/channel/UC9r5q4h1FYjSTXhmRv6lOUQ', 'authorChannelId': {'value': 'UC9r5q4h1FYjSTXhmRv6lOUQ'}, 'canRate': True, 'viewerRating': 'none', 'likeCount': 0, 'publishedAt': '2021-03-15T21:04:51Z', 'updatedAt': '2021-03-15T21:04:51Z'}}, 'canReply': True, 'totalReplyCount': 0, 'isPublic': True}}]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFnvhO0_pQtI"
      },
      "source": [
        "# Reddit PRAW"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WloiZitkplVz",
        "outputId": "2237f4dd-f840-449e-c645-c1c5271d1e65"
      },
      "source": [
        "!pip install praw"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting praw\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/a8/a2e2d0750ee17c7e3d81e4695a0338ad0b3f231853b8c3fa339ff2d25c7c/praw-7.2.0-py3-none-any.whl (159kB)\n",
            "\r\u001b[K     |██                              | 10kB 21.1MB/s eta 0:00:01\r\u001b[K     |████                            | 20kB 20.3MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 30kB 15.8MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 40kB 14.4MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 51kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 61kB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 71kB 9.9MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 81kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 92kB 10.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 102kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 112kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 122kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 133kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 143kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 153kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 163kB 8.8MB/s \n",
            "\u001b[?25hCollecting update-checker>=0.18\n",
            "  Downloading https://files.pythonhosted.org/packages/0c/ba/8dd7fa5f0b1c6a8ac62f8f57f7e794160c1f86f31c6d0fb00f582372a3e4/update_checker-0.18.0-py3-none-any.whl\n",
            "Collecting prawcore<3,>=2\n",
            "  Downloading https://files.pythonhosted.org/packages/7d/df/4a9106bea0d26689c4b309da20c926a01440ddaf60c09a5ae22684ebd35f/prawcore-2.0.0-py3-none-any.whl\n",
            "Collecting websocket-client>=0.54.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/33/80e0d4f60e84a1ddd9a03f340be1065a2a363c47ce65c4bd3bae65ce9631/websocket_client-0.58.0-py2.py3-none-any.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from update-checker>=0.18->praw) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from websocket-client>=0.54.0->praw) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->update-checker>=0.18->praw) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->update-checker>=0.18->praw) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->update-checker>=0.18->praw) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->update-checker>=0.18->praw) (2.10)\n",
            "Installing collected packages: update-checker, prawcore, websocket-client, praw\n",
            "Successfully installed praw-7.2.0 prawcore-2.0.0 update-checker-0.18.0 websocket-client-0.58.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xi-kJVIapQVO",
        "outputId": "aae17b93-99e9-4a74-fe28-6cf0f582048e"
      },
      "source": [
        "import praw\n",
        "import re\n",
        "\n",
        "#inicializar cliente de PRAW    \n",
        "reddit = praw.Reddit(\n",
        "    client_id=\"ebQ6RrLYWl4Q2Q\",\n",
        "    client_secret=\"IPMelkpgU8VtV-k70S9LqFS_99lmPw\",\n",
        "    user_agent=\"jupyter:1:1 (by /u/allicnam)\",\n",
        ")\n",
        "\n",
        "print(reddit.user.me())\n",
        "\n",
        "print(reddit.read_only)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n",
            "True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: The `None` return value is deprecated, and will raise a `ReadOnlyException` beginning with PRAW 8. See documentation for forward compatability options.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIPqnksDpsuc",
        "outputId": "1b286546-b3dc-47b8-d606-d13ea492ae45"
      },
      "source": [
        "#funcion que regresa un reditor dado el nombre de un usuario\n",
        "def getRedditor(user):\n",
        "    return reddit.redditor(user)\n",
        "\n",
        "#funcion que busca en los posts de un usuario y preprocesa el texto\n",
        "def searchByRedditor(user, limit):\n",
        "    redditor = getRedditor(user)\n",
        "    \n",
        "    posts = []\n",
        "    \n",
        "    for submission in reddit.redditor(user).submissions.new(limit=limit):\n",
        "        #eliminar hyperlinks\n",
        "        processedtext = re.sub(r'\\[(?P<word>.*?)\\].*?\\)', '\\g<word>', submission.selftext)\n",
        "        #eliminar subbreddits (r/...)\n",
        "        processedtext = re.sub(r'r\\/(?P<subr>\\w*)', '\\g<subr>', processedtext)\n",
        "        #eliminar usuarios (u/...)\n",
        "        processedtext = re.sub(r'u\\/(?P<subr>\\w*)', '', processedtext)\n",
        "        posts.append(processedtext)\n",
        "    \n",
        "    return posts\n",
        "\n",
        "#ejemplo\n",
        "print(searchByRedditor(\"spez\",5)[4])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "**TL;DR: We’re working with mods to change our content policy to explicitly address hate.**  **has resigned from our board to fill his seat with a Black candidate, a request we will honor. I want to take responsibility for the history of our policies over the years that got us here, and we still have work to do.**\n",
            "\n",
            "After watching people across the country mourn and demand an end to centuries of murder and violent discrimination against Black people, I wanted to speak out. I wanted to do this both as a human being, who sees this grief and pain and knows I have been spared from it myself because of the color of my skin, and as someone who literally has a platform and, with it, a duty to speak out.\n",
            "\n",
            "Earlier this week, I wrote an email to our company addressing this crisis and a few ways Reddit will respond. When we shared it, many of the responses said something like, “How can a company that has faced racism from users on its own platform over the years credibly take such a position?”\n",
            "\n",
            "These questions, which I know are coming from a place of real pain and which I take to heart, are really a statement: There is an unacceptable gap between our beliefs as people and a company, and what you see in our content policy. \n",
            "\n",
            "Over the last fifteen years, hundreds of millions of people have come to Reddit for things that I believe are fundamentally good: user-driven communities—across a wider spectrum of interests and passions than I could’ve imagined when we first created subreddits—and the kinds of content and conversations that keep people coming back day after day. It's why we come to Reddit as users, as mods, and as employees who want to bring this sort of community and belonging to the world and make it better daily.\n",
            "\n",
            "However, as Reddit has grown, alongside much good, it is facing its own challenges around hate and racism. We have to acknowledge and accept responsibility for the role we have played. Here are three problems we are most focused on:\n",
            "\n",
            "* Parts of Reddit reflect an unflattering but real resemblance to the world in the hate that Black users and communities see daily, despite the progress we have made in improving our tooling and enforcement. \n",
            "* Users and moderators genuinely do not have enough clarity as to where we as administrators stand on racism. \n",
            "* Our moderators are frustrated and need a real seat at the table to help shape the policies that they help us enforce.\n",
            "\n",
            "We are already working to fix these problems, and this is a promise for more urgency. Our current content policy is effectively nine rules for what you cannot do on Reddit. In many respects, it’s served us well. Under it, we have made meaningful progress cleaning up the platform (and done so without undermining the free expression and authenticity that fuels Reddit). That said, we still have work to do. This current policy lists only what you cannot do, articulates none of the values behind the rules, and does not explicitly take a stance on hate or racism.\n",
            "\n",
            "We will update our content policy to include a vision for Reddit and its communities to aspire to, a statement on hate, the context for the rules, and a principle that Reddit isn’t to be used as a weapon. We have details to work through, and while we will move quickly, I do want to be thoughtful and also gather feedback from our moderators (through our Mod Councils). With more moderator engagement, the timeline is weeks, not months.\n",
            "\n",
            "And just this morning, Alexis Ohanian (), my Reddit cofounder, announced that he is resigning from our board and that he wishes for his seat to be filled with a Black candidate, a request that the board and I will honor. We thank Alexis for this meaningful gesture and all that he’s done for us over the years.\n",
            "\n",
            "At the risk of making this unreadably long, I'd like to take this moment to share how we got here in the first place, where we have made progress, and where, despite our best intentions, we have fallen short.\n",
            "\n",
            "In the early days of Reddit, 2005–2006, our idealistic “policy” was that, excluding spam, we would not remove content. We were small and did not face many hard decisions. When this ideal was tested, we banned racist users anyway. In the end, we acted based on our beliefs, despite our “policy.” \n",
            "\n",
            "I left Reddit from 2010–2015. During this time, in addition to rapid user growth, Reddit’s no-removal policy ossified and its content policy took no position on hate. \n",
            "\n",
            "When I returned in 2015, my top priority was creating a content policy to do two things: deal with hateful communities I had been immediately confronted with (like CoonTown, which was explicitly designed to spread racist hate) and provide a clear policy of what’s acceptable on Reddit and what’s not. We banned that community and others because they were “making Reddit worse” but were not clear and direct about their role in sowing hate. We crafted our 2015 policy around behaviors adjacent to hate that were actionable and objective: violence and harassment, because we struggled to create a definition of hate and racism that we could defend and enforce at our scale. Through continual updates to these policies 2017, 2018, 2019, 2020 (and a broader definition of violence), we have removed thousands of hateful communities. \n",
            "\n",
            "While we dealt with many communities themselves, we still did not provide the clarity—and it showed, both in our enforcement and in confusion about where we stand. In 2018, I confusingly said racism is not against the rules, but also isn’t welcome on Reddit. This gap between our content policy and our values has eroded our effectiveness in combating hate and racism on Reddit; I accept full responsibility for this.\n",
            "\n",
            "This inconsistency has hurt our trust with our users and moderators and has made us slow to respond to problems. This was also true with the_donald, a community that relished in exploiting and detracting from the best of Reddit and that is now nearly disintegrated on their own accord. As we looked to our policies, “Breaking Reddit” was not a sufficient explanation for actioning a political subreddit, and I fear we let being technically correct get in the way of doing the right thing. Clearly, we should have quarantined it sooner.\n",
            "\n",
            "The majority of our top communities have a rule banning hate and racism, which makes us proud, and is evidence why a community-led approach is the only way to scale moderation online. That said, this is not a rule communities should have to write for themselves and we need to rebalance the burden of enforcement. I also accept responsibility for this. \n",
            "\n",
            "Despite making significant progress over the years, we have to turn a mirror on ourselves and be willing to do the hard work of making sure we are living up to our values in our product and policies. This is a significant moment. We have a choice: return to the status quo or use this opportunity for change. We at Reddit are opting for the latter, and we will do our very best to be a part of the progress.\n",
            "\n",
            "I will be sticking around for a while to answer questions as usual, but I also know that our policies and actions will speak louder than our comments.\n",
            "\n",
            "Thanks,\n",
            "\n",
            "Steve\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hm6-HAOT1ork"
      },
      "source": [
        "# RNN ARCHITECTURES\n",
        "En esta sección se entrenar diferentes redes neuronales para su implementación en el analisis de sentimiento, Se puede ver cada una de las diferentes arquitecturas e hiper-parametros que se intentaron para lograr una mejor accuracy. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPGKb8u3qXPC"
      },
      "source": [
        "\n",
        "\n",
        "# DATA CLEANSING\n",
        "En esta sección se limpia y se divide los datos con los que se va a entrenar y validar las redes neuronales recurrentes\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJE327LWsmX_",
        "outputId": "873715d6-4f96-4e64-ee8b-0fb4c7f3d014"
      },
      "source": [
        "import nltk\n",
        "import string\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHCv9JwG1um0",
        "outputId": "f559d203-3864-49f9-8a4e-6b26c5b7d172"
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/My Drive\")\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " bert\t     BRRN_LSTM.h5\t 'Colab Notebooks'   rnn_bi     rnn_LSTM.h5\n",
            " Bert_test   client-secret.json   Datasets\t     rnn_lstm   rnn_simple.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "SLzLStbAqcLv",
        "outputId": "5b45e6fc-b291-4fd0-df4d-6111f75f630b"
      },
      "source": [
        "import pandas as pd\n",
        "data_train=pd.read_csv('Datasets/train.csv')\n",
        "data_test=pd.read_csv('Datasets/test.csv')\n",
        "data_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>@fbfh Gotta love ebay! I sell collectibles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>@AKAVirtualPA http://twitpic.com/4bckp - that ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>facebook and pfc are being lameeee.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>stayed up to late watching tv. Getting the gir...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>watching Buffy with my Nana.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1199994</th>\n",
              "      <td>1</td>\n",
              "      <td>counting down the days...3 days until roadtrip...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1199995</th>\n",
              "      <td>1</td>\n",
              "      <td>http://twitpic.com/4x082 - Is this our dog, is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1199996</th>\n",
              "      <td>1</td>\n",
              "      <td>member services guide, gala invite, sunny mond...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1199997</th>\n",
              "      <td>1</td>\n",
              "      <td>@Dougrea I wish I knew brother</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1199998</th>\n",
              "      <td>0</td>\n",
              "      <td>Why is my sister and my Ate taking soo long to...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1199999 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         label                                               text\n",
              "0            1        @fbfh Gotta love ebay! I sell collectibles \n",
              "1            1  @AKAVirtualPA http://twitpic.com/4bckp - that ...\n",
              "2            0               facebook and pfc are being lameeee. \n",
              "3            0  stayed up to late watching tv. Getting the gir...\n",
              "4            1                      watching Buffy with my Nana. \n",
              "...        ...                                                ...\n",
              "1199994      1  counting down the days...3 days until roadtrip...\n",
              "1199995      1  http://twitpic.com/4x082 - Is this our dog, is...\n",
              "1199996      1  member services guide, gala invite, sunny mond...\n",
              "1199997      1                    @Dougrea I wish I knew brother \n",
              "1199998      0  Why is my sister and my Ate taking soo long to...\n",
              "\n",
              "[1199999 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6dH5uaUB8ZK"
      },
      "source": [
        "REMOVE HYPERLINKS\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yj-V55xn8m4D"
      },
      "source": [
        "   data_train['text'] = data_train['text'].str.replace('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' ')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "GHPf3qex8TE1",
        "outputId": "f571caf0-554c-4b64-d9fb-e3fdb00033d0"
      },
      "source": [
        "data_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>@fbfh Gotta love ebay! I sell collectibles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>@AKAVirtualPA   - that should answer part of y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>facebook and pfc are being lameeee.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>stayed up to late watching tv. Getting the gir...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>watching Buffy with my Nana.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1199994</th>\n",
              "      <td>1</td>\n",
              "      <td>counting down the days...3 days until roadtrip...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1199995</th>\n",
              "      <td>1</td>\n",
              "      <td>- Is this our dog, is is?  I guess not until...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1199996</th>\n",
              "      <td>1</td>\n",
              "      <td>member services guide, gala invite, sunny mond...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1199997</th>\n",
              "      <td>1</td>\n",
              "      <td>@Dougrea I wish I knew brother</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1199998</th>\n",
              "      <td>0</td>\n",
              "      <td>Why is my sister and my Ate taking soo long to...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1199999 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         label                                               text\n",
              "0            1        @fbfh Gotta love ebay! I sell collectibles \n",
              "1            1  @AKAVirtualPA   - that should answer part of y...\n",
              "2            0               facebook and pfc are being lameeee. \n",
              "3            0  stayed up to late watching tv. Getting the gir...\n",
              "4            1                      watching Buffy with my Nana. \n",
              "...        ...                                                ...\n",
              "1199994      1  counting down the days...3 days until roadtrip...\n",
              "1199995      1    - Is this our dog, is is?  I guess not until...\n",
              "1199996      1  member services guide, gala invite, sunny mond...\n",
              "1199997      1                    @Dougrea I wish I knew brother \n",
              "1199998      0  Why is my sister and my Ate taking soo long to...\n",
              "\n",
              "[1199999 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mex1xL5qcD7"
      },
      "source": [
        "\n",
        "import re\n",
        "\n",
        "# REMOVE PUNCTUATION\n",
        "words = data_train['text']\n",
        "\n",
        "table = str.maketrans('', '', string.punctuation)\n",
        "data_train['text'] = [w.translate(table) for w in words]\n",
        "\n",
        "\n",
        "# remove remaining tokens that are not alphabetic\n",
        "words = [word for word in words if word.isalpha()]\n",
        "# filter out stop words\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "words = [w for w in words if not w in stop_words]\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "86kqo7QX4j7j",
        "outputId": "41ca4c82-70ab-4e63-a488-6c235152de61"
      },
      "source": [
        "data_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>fbfh Gotta love ebay I sell collectibles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>AKAVirtualPA    that should answer part of you...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>facebook and pfc are being lameeee</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>stayed up to late watching tv Getting the girl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>watching Buffy with my Nana</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                               text\n",
              "0      1          fbfh Gotta love ebay I sell collectibles \n",
              "1      1  AKAVirtualPA    that should answer part of you...\n",
              "2      0                facebook and pfc are being lameeee \n",
              "3      0  stayed up to late watching tv Getting the girl...\n",
              "4      1                       watching Buffy with my Nana "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmxDFYnwuYb5"
      },
      "source": [
        "data_train.to_csv('Datasets/data_trainsinlinks.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUlUJhxAI667"
      },
      "source": [
        "data_test['text'] = data_test['text'].str.replace('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' ')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKRFaGfqI7IM"
      },
      "source": [
        "\n",
        "# REMOVE PUNCTUATION\n",
        "words = data_test['text']\n",
        "\n",
        "table = str.maketrans('', '', string.punctuation)\n",
        "data_test['text'] = [w.translate(table) for w in words]\n",
        "\n",
        "\n",
        "# remove remaining tokens that are not alphabetic\n",
        "words = [word for word in words if word.isalpha()]\n",
        "# filter out stop words\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "words = [w for w in words if not w in stop_words]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtUTF79EuzZy"
      },
      "source": [
        "data_test.to_csv('Datasets/data_testsinlinks.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "9aTikY1AqcUf",
        "outputId": "d6c5f416-a595-4044-e6d4-3a6a8e3ded4e"
      },
      "source": [
        "data_test.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>I just love the rain It cools everything down ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>RandiElaine nope jus me she cant touch me  She...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>getting VERY sleepy    singing quotBirthday Se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>DavidArchie s now 3rd Hahah  Keep voting guys</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Sutto coffee is on the way</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>lsshahailove the song of neyo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>Heading to drop 2 vans full of girls off at Su...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>CandyOmatic Wait Nines deleting all of us  Boooo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>Mabetini hugs i have no words sweetie im sorry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>Killandra Reading amp loving it Boy are u righ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                               text\n",
              "0      1  I just love the rain It cools everything down ...\n",
              "1      0  RandiElaine nope jus me she cant touch me  She...\n",
              "2      1  getting VERY sleepy    singing quotBirthday Se...\n",
              "3      1   DavidArchie s now 3rd Hahah  Keep voting guys   \n",
              "4      1                        Sutto coffee is on the way \n",
              "5      1                   lsshahailove the song of neyo   \n",
              "6      1  Heading to drop 2 vans full of girls off at Su...\n",
              "7      0   CandyOmatic Wait Nines deleting all of us  Boooo\n",
              "8      0    Mabetini hugs i have no words sweetie im sorry \n",
              "9      0  Killandra Reading amp loving it Boy are u righ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csycaBGnTEL8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sI-1P951cFqk",
        "outputId": "8fd9521a-b260-41c0-9d89-47c4b371996e"
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive\")\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " bert   Bert_test  'Colab Notebooks'   Datasets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5-8Oi00emxK"
      },
      "source": [
        "train=pd.read_csv('/Datasets/train.csv')\n",
        "x_train=train.text.to_numpy()\n",
        "y_train=train.label.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Go82f8SCe511"
      },
      "source": [
        "test=pd.read_csv('/Datasets/test.csv')\n",
        "x_test=test.text.to_numpy()\n",
        "y_test=test.label.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oG6gPie6goBg"
      },
      "source": [
        "train=pd.read_csv('/Datasets/data_train.csv')\n",
        "x_train=train[train.columns[1]].to_numpy()\n",
        "y_train=train[train.columns[0]].to_numpy()\n",
        "test=pd.read_csv('/Datasets/data_test.csv')\n",
        "x_test=test[test.columns[1]].to_numpy()\n",
        "y_test=test[test.columns[0]].to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzDw1LO4ESzk"
      },
      "source": [
        "x_test=x_train[40000:44000]\n",
        "y_test=y_train[40000:44000]\n",
        "x_train=x_train[10000:40000]\n",
        "y_train=y_train[10000:40000]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hisD-cYQgYMU"
      },
      "source": [
        " Se transforma el texto como input en una secuencia de numeros que pueda ser procesada por las redes neuronales"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4MKdXONpxZl"
      },
      "source": [
        "max_features = 5000\n",
        "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "X = tokenizer.texts_to_sequences(x_train)\n",
        "X_train = pad_sequences(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "dpQv9iNgfCPL",
        "outputId": "65bdb222-b4d6-4a41-c734-9dc1041dbb9a"
      },
      "source": [
        "max_features = 5000\n",
        "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
        "tokenizer.fit_on_texts(x_test)\n",
        "X = tokenizer.texts_to_sequences(x_test)\n",
        "X_test = pad_sequences(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-db574f54854f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_on_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/preprocessing/sequence.py\u001b[0m in \u001b[0;36mpad_sequences\u001b[0;34m(sequences, maxlen, dtype, padding, truncating, value)\u001b[0m\n\u001b[1;32m    156\u001b[0m   return sequence.pad_sequences(\n\u001b[1;32m    157\u001b[0m       \u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m       padding=padding, truncating=truncating, value=value)\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m keras_export(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_preprocessing/sequence.py\u001b[0m in \u001b[0;36mpad_sequences\u001b[0;34m(sequences, maxlen, dtype, padding, truncating, value)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmaxlen\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mmaxlen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mis_dtype_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0municode_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mamax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2704\u001b[0m     \"\"\"\n\u001b[1;32m   2705\u001b[0m     return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n\u001b[0;32m-> 2706\u001b[0;31m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0m\u001b[1;32m   2707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_Y-BovsDsGJ"
      },
      "source": [
        "# Simple RNN \n",
        "Recurrent neural network is a type of neural network used to deal specifically with sequential data. Actually what makes RNN so powerful is the fact that it doesn't take into consideration just the actual input but also the previous input which allows it to memorize what happens previously. To get a better intuition on RNN let’s take the example of text classification, for this task we can use the classic machine learning algorithms like naive bayes but the problem with this algorithm, it takes a sentence as a set of independent words and precisely the frequency of each word without worrying about the composition of words or the order of words in a sentence which makes a huge difference to form the meaning of a sentence. RNN unlike those classic algorithms, works well on sequence data because it takes the word i as input and combine with the output of word i-1, the same thing would be applied for word i+1 and this is the reason it’s called recurrent neural network because clearly the neural network apply the same operations on each word i of the sentence\n",
        "\n",
        "Ref=https://medium.com/swlh/simple-explanation-of-recurrent-neural-network-rnn-1285749cc363\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efNamuFqnV4u"
      },
      "source": [
        "from keras.preprocessing import sequence\n",
        "max_words = 500\n",
        "vocabulary_size=1000\n",
        "train=pd.read_csv('/Datasets/data_trainsinlinks.csv')\n",
        "test=pd.read_csv('/Datasets/data_testsinlinks.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "1gUcCmXBovWG",
        "outputId": "9dd7fb76-de58-43bf-dfa1-83bf06267933"
      },
      "source": [
        "train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>fbfh Gotta love ebay I sell collectibles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>AKAVirtualPA    that should answer part of you...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>facebook and pfc are being lameeee</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>stayed up to late watching tv Getting the girl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>watching Buffy with my Nana</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1199994</th>\n",
              "      <td>1199994</td>\n",
              "      <td>1</td>\n",
              "      <td>counting down the days3 days until roadtrip se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1199995</th>\n",
              "      <td>1199995</td>\n",
              "      <td>1</td>\n",
              "      <td>Is this our dog is is  I guess not until I ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1199996</th>\n",
              "      <td>1199996</td>\n",
              "      <td>1</td>\n",
              "      <td>member services guide gala invite sunny monday...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1199997</th>\n",
              "      <td>1199997</td>\n",
              "      <td>1</td>\n",
              "      <td>Dougrea I wish I knew brother</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1199998</th>\n",
              "      <td>1199998</td>\n",
              "      <td>0</td>\n",
              "      <td>Why is my sister and my Ate taking soo long to...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1199999 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         Unnamed: 0  label                                               text\n",
              "0                 0      1          fbfh Gotta love ebay I sell collectibles \n",
              "1                 1      1  AKAVirtualPA    that should answer part of you...\n",
              "2                 2      0                facebook and pfc are being lameeee \n",
              "3                 3      0  stayed up to late watching tv Getting the girl...\n",
              "4                 4      1                       watching Buffy with my Nana \n",
              "...             ...    ...                                                ...\n",
              "1199994     1199994      1  counting down the days3 days until roadtrip se...\n",
              "1199995     1199995      1     Is this our dog is is  I guess not until I ...\n",
              "1199996     1199996      1  member services guide gala invite sunny monday...\n",
              "1199997     1199997      1                     Dougrea I wish I knew brother \n",
              "1199998     1199998      0  Why is my sister and my Ate taking soo long to...\n",
              "\n",
              "[1199999 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7enLabJFoiVS"
      },
      "source": [
        "x_train=train.text.to_numpy()\n",
        "y_train=train.label.to_numpy()\n",
        "x_test=test.text.to_numpy()\n",
        "y_test=test.label.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqk5mIgJq-YP"
      },
      "source": [
        "max_features = 1000\n",
        "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "X = tokenizer.texts_to_sequences(x_train)\n",
        "X_train = pad_sequences(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdW-TMBErJkr"
      },
      "source": [
        "max_features = 1000\n",
        "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
        "tokenizer.fit_on_texts(x_test)\n",
        "X = tokenizer.texts_to_sequences(x_test)\n",
        "X_test = pad_sequences(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w83os7Enq-hR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpFA3qCenHvp",
        "outputId": "d082ba2f-d6c2-486d-aefe-680ca2cde25f"
      },
      "source": [
        "#Modelo RNN\n",
        "from keras import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "\n",
        "#La capa de output necesita ser una Dense lAYER\n",
        "embedding_size=64\n",
        "model=Sequential()\n",
        "model.add(Embedding(vocabulary_size, embedding_size, input_length=max_words))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 500, 64)           64000     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 500, 1)            65        \n",
            "=================================================================\n",
            "Total params: 64,065\n",
            "Trainable params: 64,065\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bf92hTzfnHzv"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', \n",
        "             optimizer='adam', \n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKHz2vibnH3Z",
        "outputId": "76744258-aea8-45f1-df27-cfd30ba2ae04"
      },
      "source": [
        "batch_size = 128\n",
        "model.fit(X_train, y_train, epochs = 3, batch_size=batch_size, verbose = 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 500) for input KerasTensor(type_spec=TensorSpec(shape=(None, 500), dtype=tf.float32, name='embedding_3_input'), name='embedding_3_input', description=\"created by layer 'embedding_3_input'\"), but it was called on an input with incompatible shape (None, 40).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 500) for input KerasTensor(type_spec=TensorSpec(shape=(None, 500), dtype=tf.float32, name='embedding_3_input'), name='embedding_3_input', description=\"created by layer 'embedding_3_input'\"), but it was called on an input with incompatible shape (None, 40).\n",
            "9375/9375 - 30s - loss: 0.6863 - accuracy: 0.5253\n",
            "Epoch 2/3\n",
            "9375/9375 - 30s - loss: 0.6861 - accuracy: 0.5266\n",
            "Epoch 3/3\n",
            "9375/9375 - 29s - loss: 0.6860 - accuracy: 0.5270\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd4e7172ad0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sis0axG2DjH4",
        "outputId": "112dae82-22ab-44b8-d439-c3d146aaebda"
      },
      "source": [
        "#Creción de modelo RNN Simple\n",
        "embed_dim = 128\n",
        "max_fatures = 5000\n",
        "modelRNN = keras.Sequential()\n",
        "modelRNN.add(layers.Embedding(max_fatures, embed_dim, input_length = X_train.shape[1]))\n",
        "# The output of GRU will be a 3D tensor of shape (batch_size, timesteps, 256)\n",
        "modelRNN.add(layers.GRU(256, return_sequences=True,kernel_regularizer=regularizers.l1_l2(l1=5e-3, l2=9e-4),\n",
        "    bias_regularizer=regularizers.l2(1e-4),\n",
        "    activity_regularizer=regularizers.l2(1e-5)))\n",
        "# The output of SimpleRNN will be a 2D tensor of shape (batch_size, 128)\n",
        "modelRNN.add(layers.SimpleRNN(128,kernel_regularizer=regularizers.l1_l2(l1=5e-4, l2=5e-4),\n",
        "    bias_regularizer=regularizers.l2(1e-4),\n",
        "    activity_regularizer=regularizers.l2(1e-5)))\n",
        "modelRNN.add(layers.Dense(1,activation='sigmoid',kernel_regularizer=regularizers.l1_l2(l1=5e-4, l2=5e-4),\n",
        "    bias_regularizer=regularizers.l2(1e-4),activity_regularizer=regularizers.l2(1e-5)))\n",
        "modelRNN.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "modelRNN.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 33, 128)           640000    \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 33, 256)           296448    \n",
            "_________________________________________________________________\n",
            "simple_rnn_1 (SimpleRNN)     (None, 128)               49280     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 985,857\n",
            "Trainable params: 985,857\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_d7G56adPyu",
        "outputId": "b2ee93a3-9141-4fe8-9325-290fe1b85cfe"
      },
      "source": [
        "#Entrenamiento del modelo\n",
        "batch_size = 128\n",
        "modelRNN.fit(X_train, y_train, epochs = 7, batch_size=batch_size, verbose = 2)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/7\n",
            "157/157 - 7s - loss: 4.8002 - accuracy: 0.5112\n",
            "Epoch 2/7\n",
            "157/157 - 5s - loss: 0.7603 - accuracy: 0.4965\n",
            "Epoch 3/7\n",
            "157/157 - 5s - loss: 0.7576 - accuracy: 0.4996\n",
            "Epoch 4/7\n",
            "157/157 - 5s - loss: 0.7558 - accuracy: 0.5020\n",
            "Epoch 5/7\n",
            "157/157 - 5s - loss: 0.7551 - accuracy: 0.4963\n",
            "Epoch 6/7\n",
            "157/157 - 5s - loss: 0.7547 - accuracy: 0.5020\n",
            "Epoch 7/7\n",
            "157/157 - 5s - loss: 0.7546 - accuracy: 0.5020\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7facc2861150>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "LiHKQDicVbpU",
        "outputId": "37060c73-81b1-4a70-ddcf-39db8d7bf781"
      },
      "source": [
        "#Se checa el acurracy\n",
        "print('Simple RNN Network accuracy test')\n",
        "score,acc = modelRNN.evaluate(X_test, y_test, verbose = 2, batch_size = batch_size)\n",
        "modelRNN.save('rnn_simple.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Simple RNN Network accuracy test\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-86ceb99eaccb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Simple RNN Network accuracy test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelRNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#modelRNN.save('rnn_simple.h5')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpzMPbT7Joe2"
      },
      "source": [
        "# Modelo 2 RNN\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CooHiVGNJnZb"
      },
      "source": [
        "import pandas as pd\n",
        "train=pd.read_csv('/content/drive/MyDrive/Datasets/data_trainsinlinks.csv')\n",
        "x_train=train[train.columns[1]].to_numpy()\n",
        "y_train=train[train.columns[0]].to_numpy()\n",
        "test=pd.read_csv('/content/drive/MyDrive/Datasets/data_testsinlinks.csv')\n",
        "x_test=test[test.columns[1]].to_numpy()\n",
        "y_test=test[test.columns[0]].to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bp78lf4cJncn"
      },
      "source": [
        "max_features = 2000\n",
        "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "X = tokenizer.texts_to_sequences(x_train)\n",
        "X_train = pad_sequences(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QU2xUe3EJnfu"
      },
      "source": [
        "max_features = 2000\n",
        "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
        "tokenizer.fit_on_texts(x_test)\n",
        "X = tokenizer.texts_to_sequences(x_test)\n",
        "X_test = pad_sequences(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_qZenyxJns8",
        "outputId": "1cd52f26-58ca-4b27-f43a-d65ca35dbe36"
      },
      "source": [
        "#Creación del modelo\n",
        "embed_dim = 128\n",
        "max_fatures = 2000\n",
        "modelRNN = keras.Sequential()\n",
        "modelRNN.add(layers.Embedding(max_fatures, embed_dim, input_length = X_train.shape[1]))\n",
        "# The output of GRU will be a 3D tensor of shape (batch_size, timesteps, 256)\n",
        "modelRNN.add(layers.GRU(256, return_sequences=True))\n",
        "# The output of SimpleRNN will be a 2D tensor of shape (batch_size, 128)\n",
        "modelRNN.add(layers.SimpleRNN(128))\n",
        "modelRNN.add(layers.Dense(1,activation='sigmoid'))\n",
        "modelRNN.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "modelRNN.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 40, 128)           256000    \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, 40, 256)           296448    \n",
            "_________________________________________________________________\n",
            "simple_rnn (SimpleRNN)       (None, 128)               49280     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 601,857\n",
            "Trainable params: 601,857\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibe0GCx_KeRi",
        "outputId": "3f63bc2e-ac24-4820-cf8d-460dec65c2cf"
      },
      "source": [
        "batch_size = 128\n",
        "modelRNN.fit(X_train, y_train, epochs = 7, batch_size=batch_size, verbose = 2)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/7\n",
            "9375/9375 - 290s - loss: 0.4453 - accuracy: 0.7900\n",
            "Epoch 2/7\n",
            "9375/9375 - 260s - loss: 0.4174 - accuracy: 0.8062\n",
            "Epoch 3/7\n",
            "9375/9375 - 260s - loss: 0.4033 - accuracy: 0.8139\n",
            "Epoch 4/7\n",
            "9375/9375 - 260s - loss: 0.3926 - accuracy: 0.8201\n",
            "Epoch 5/7\n",
            "9375/9375 - 259s - loss: 0.3847 - accuracy: 0.8248\n",
            "Epoch 6/7\n",
            "9375/9375 - 260s - loss: 0.3772 - accuracy: 0.8291\n",
            "Epoch 7/7\n",
            "9375/9375 - 259s - loss: 0.3697 - accuracy: 0.8327\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7febdb268890>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7sRcyRbLJhM",
        "outputId": "3d5a1202-dfcd-483f-8325-0e8a724e072b"
      },
      "source": [
        "print('Simple RNN Network accuracy test')\n",
        "score,acc = modelRNN.evaluate(X_test, y_test, verbose = 2, batch_size = batch_size)\n",
        "#modelRNN.save('rnn_simple.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Simple RNN Network accuracy test\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 40) for input KerasTensor(type_spec=TensorSpec(shape=(None, 40), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None, 34).\n",
            "3125/3125 - 13s - loss: 0.8454 - accuracy: 0.5896\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1So8_QLLJpC",
        "outputId": "f66eb416-9255-489a-d87f-a766d8d50c9d"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(399999, 34)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KP1k7ToEbTqD"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7P3GQVBbQ3f"
      },
      "source": [
        "# Modelo 3 RNN\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JyIOyvHLJzT"
      },
      "source": [
        "max_features = 1000\n",
        "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "X = tokenizer.texts_to_sequences(x_train)\n",
        "X_train = pad_sequences(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M49a0gZ5LJ2r"
      },
      "source": [
        "max_features = 1000\n",
        "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
        "tokenizer.fit_on_texts(x_test)\n",
        "X = tokenizer.texts_to_sequences(x_test)\n",
        "X_test = pad_sequences(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxfMHgzFdbpe",
        "outputId": "657138f2-c8d8-4cfa-ee32-0554492e9445"
      },
      "source": [
        "embed_dim = 128\n",
        "max_fatures = 2000\n",
        "modelRNN = keras.Sequential()\n",
        "modelRNN.add(layers.Embedding(max_fatures, embed_dim, input_length = X_train.shape[1]))\n",
        "# The output of GRU will be a 3D tensor of shape (batch_size, timesteps, 256)\n",
        "modelRNN.add(layers.GRU(256, return_sequences=True))\n",
        "# The output of SimpleRNN will be a 2D tensor of shape (batch_size, 128)\n",
        "modelRNN.add(layers.SimpleRNN(128))\n",
        "modelRNN.add(layers.Dense(1,activation='sigmoid'))\n",
        "modelRNN.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "modelRNN.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 40, 128)           256000    \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 40, 256)           296448    \n",
            "_________________________________________________________________\n",
            "simple_rnn_1 (SimpleRNN)     (None, 128)               49280     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 601,857\n",
            "Trainable params: 601,857\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "b2czMACidbwF",
        "outputId": "08ce9419-6341-4649-bc61-7c5322679296"
      },
      "source": [
        "batch_size = 128\n",
        "modelRNN.fit(X_train, y_train, epochs = 7, batch_size=batch_size, verbose = 2)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/7\n",
            "9375/9375 - 262s - loss: 0.3853 - accuracy: 0.8228\n",
            "Epoch 2/7\n",
            "9375/9375 - 261s - loss: 0.3862 - accuracy: 0.8223\n",
            "Epoch 3/7\n",
            "9375/9375 - 262s - loss: 0.3891 - accuracy: 0.8205\n",
            "Epoch 4/7\n",
            "9375/9375 - 261s - loss: 0.3926 - accuracy: 0.8187\n",
            "Epoch 5/7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-f4f59a1a016d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodelRNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHJ0kfo9e99g"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTReT2PqEM69"
      },
      "source": [
        "# LSTM (Long Short-Term Memory) networks\n",
        "\n",
        "Long Short Term Memory networks – usually just called “LSTMs” – are a special kind of RNN, capable of learning long-term dependencies. They were introduced by Hochreiter & Schmidhuber (1997), and were refined and popularized by many people in following work.1 They work tremendously well on a large variety of problems, and are now widely used.\n",
        "\n",
        "LSTMs are explicitly designed to avoid the long-term dependency problem. Remembering information for long periods of time is practically their default behavior, not something they struggle to learn!\n",
        "\n",
        "Ref=https://colah.github.io/posts/2015-08-Understanding-LSTMs/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLFst3DcELaC",
        "outputId": "b603f3d6-c32d-445d-f452-69968ac32265"
      },
      "source": [
        "#Creaión del módelo LSTM\n",
        "embed_dim = 128\n",
        "lstm_out = 196\n",
        "\n",
        "model = keras.Sequential()\n",
        "\n",
        "model.add(layers.Embedding(max_features, embed_dim, input_length = X_train.shape[1]))\n",
        "\n",
        "model.add(layers.SpatialDropout1D(0.4))\n",
        "\n",
        "model.add(layers.LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
        "\n",
        "model.add(layers.Dense(1,activation='sigmoid'))\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 37, 128)           256000    \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_1 (Spatial (None, 37, 128)           0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 196)               254800    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 197       \n",
            "=================================================================\n",
            "Total params: 510,997\n",
            "Trainable params: 510,997\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "2-ypRAUSaSud",
        "outputId": "4db99731-f0ce-427d-d9c2-f05e96f15944"
      },
      "source": [
        "batch_size = 128\n",
        "model.fit(X_train, y_train, epochs = 7, batch_size=batch_size, verbose = 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-cc0921baa0a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gY2b41C7aSys",
        "outputId": "5e99aaf2-6864-412e-ea38-ed4599e6a547"
      },
      "source": [
        "model.save('rnn_LSTM.h5')\n",
        "print('LSTM RNN Network accuracy test')\n",
        "score,acc = model.evaluate(X_test, y_test, verbose = 2, batch_size = batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LSTM RNN Network accuracy test\n",
            "40/40 - 3s - loss: 1.8554 - accuracy: 0.5350\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLYgt8kFtqk4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdTReo57t71U"
      },
      "source": [
        "# *Modelo* 2 LSTM\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8E3M4ueuwt6"
      },
      "source": [
        "import pandas as pd\n",
        "train=pd.read_csv('/content/drive/MyDrive/Datasets/data_trainsinlinks.csv')\n",
        "x_train=train[train.columns[1]].to_numpy()\n",
        "y_train=train[train.columns[0]].to_numpy()\n",
        "test=pd.read_csv('/content/drive/MyDrive/Datasets/data_testsinlinks.csv')\n",
        "x_test=test[test.columns[1]].to_numpy()\n",
        "y_test=test[test.columns[0]].to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLILsysHuw3N"
      },
      "source": [
        "max_features = 2000\n",
        "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "X = tokenizer.texts_to_sequences(x_train)\n",
        "X_train = pad_sequences(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfmQKzOLuw-r"
      },
      "source": [
        "max_features = 2000\n",
        "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
        "tokenizer.fit_on_texts(x_test)\n",
        "X = tokenizer.texts_to_sequences(x_test)\n",
        "X_test = pad_sequences(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaHaH7Vdu8jC",
        "outputId": "884f5dc3-7eb4-418b-e2a8-83c44fb348a8"
      },
      "source": [
        "embed_dim = 128\n",
        "lstm_out = 196\n",
        "\n",
        "model = keras.Sequential()\n",
        "\n",
        "model.add(layers.Embedding(max_features, embed_dim, input_length = X_train.shape[1]))\n",
        "\n",
        "model.add(layers.SpatialDropout1D(0.4))\n",
        "\n",
        "model.add(layers.LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
        "\n",
        "model.add(layers.Dense(1,activation='sigmoid'))\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 40, 128)           256000    \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_1 (Spatial (None, 40, 128)           0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 196)               254800    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 197       \n",
            "=================================================================\n",
            "Total params: 510,997\n",
            "Trainable params: 510,997\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMtnNqGdv0Dn",
        "outputId": "b3e602a8-f41f-4a21-acf2-0f692b36cc1f"
      },
      "source": [
        "print('LSTM RNN Network accuracy test')\n",
        "score,acc = model.evaluate(X_test, y_test, verbose = 2, batch_size = batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LSTM RNN Network accuracy test\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 40) for input KerasTensor(type_spec=TensorSpec(shape=(None, 40), dtype=tf.float32, name='embedding_3_input'), name='embedding_3_input', description=\"created by layer 'embedding_3_input'\"), but it was called on an input with incompatible shape (None, 34).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 40) for input KerasTensor(type_spec=TensorSpec(shape=(None, 40), dtype=tf.float32, name='embedding_3_input'), name='embedding_3_input', description=\"created by layer 'embedding_3_input'\"), but it was called on an input with incompatible shape (None, 34).\n",
            "3125/3125 - 24s - loss: 0.6931 - accuracy: 0.5057\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvTHQVp1Ei3s"
      },
      "source": [
        "# Bidirectional LSTM (BRNN)\n",
        "\n",
        "The idea of Bidirectional Recurrent Neural Networks (RNNs) is straightforward.\n",
        "It involves duplicating the first recurrent layer in the network so that there are now two layers side-by-side, then providing the input sequence as-is as input to the first layer and providing a reversed copy of the input sequence to the second.\n",
        "\n",
        "This approach has been used to great effect with Long Short-Term Memory (LSTM) Recurrent Neural Networks.\n",
        "The use of providing the sequence bi-directionally was initially justified in the domain of speech recognition because there is evidence that the context of the whole utterance is used to interpret what is being said rather than a linear interpretation.\n",
        "\n",
        "ref=https://machinelearningmastery.com/develop-bidirectional-lstm-sequence-classification-python-keras/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vkIo0MNEh8A",
        "outputId": "509d3811-9368-4d08-cba3-3c39a9c58567"
      },
      "source": [
        "\n",
        "modelBRNN = keras.Sequential()\n",
        "modelBRNN.add(layers.Bidirectional(layers.LSTM(20, return_sequences=True), input_shape=(1,X_train.shape[1])))\n",
        "modelBRNN.add(layers.TimeDistributed(layers.Dense(1, activation='sigmoid')))\n",
        "modelBRNN.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# train LSTM\n",
        "modelBRNN.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_29\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bidirectional (Bidirectional (None, 1, 40)             8320      \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 1, 1)              41        \n",
            "=================================================================\n",
            "Total params: 8,361\n",
            "Trainable params: 8,361\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W10l7Azod7iC",
        "outputId": "0c75a2bc-23d8-459a-8596-25cbc7d76cc0"
      },
      "source": [
        "batch_size =128\n",
        "modelBRNN.fit(np.array([X_train]), np.array([np.array(y_train).reshape(-1,1)]), epochs = 7, batch_size=batch_size, verbose = 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/7\n",
            "1/1 - 8s - loss: 0.6994 - accuracy: 0.5337\n",
            "Epoch 2/7\n",
            "1/1 - 8s - loss: 0.6984 - accuracy: 0.5348\n",
            "Epoch 3/7\n",
            "1/1 - 8s - loss: 0.6974 - accuracy: 0.5356\n",
            "Epoch 4/7\n",
            "1/1 - 8s - loss: 0.6965 - accuracy: 0.5369\n",
            "Epoch 5/7\n",
            "1/1 - 8s - loss: 0.6956 - accuracy: 0.5371\n",
            "Epoch 6/7\n",
            "1/1 - 8s - loss: 0.6947 - accuracy: 0.5376\n",
            "Epoch 7/7\n",
            "1/1 - 8s - loss: 0.6939 - accuracy: 0.5395\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f17358d0690>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Rt3IRqX5eXx7",
        "outputId": "ac12c92c-277d-4fc0-b37c-5c9116b1a0ee"
      },
      "source": [
        "model.save('BRRN_LSTM.h5')\n",
        "print('BRNN Network accuracy test')\n",
        "score,acc = modelBRNN.evaluate(np.array([X_test]), np.array([np.array(y_test).reshape(-1,1)]), verbose = 2, batch_size = batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BRNN Network accuracy test\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 1, 31) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 31), dtype=tf.float32, name='bidirectional_input'), name='bidirectional_input', description=\"created by layer 'bidirectional_input'\"), but it was called on an input with incompatible shape (None, 5000, 30).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-180-202051d7a565>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'BRRN_LSTM.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'BRNN Network accuracy test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelBRNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1387\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1233 test_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1224 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1217 run_step  **\n        outputs = model.test_step(data)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1183 test_step\n        y_pred = self(x, training=False)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:1012 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:375 call\n        return super(Sequential, self).call(inputs, training=training, mask=mask)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:425 call\n        inputs, training=training, mask=mask)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:560 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/wrappers.py:539 __call__\n        return super(Bidirectional, self).__call__(inputs, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:1012 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/wrappers.py:653 call\n        initial_state=forward_state, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/recurrent.py:660 __call__\n        return super(RNN, self).__call__(inputs, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/input_spec.py:274 assert_input_compatibility\n        ', found shape=' + display_shape(x.shape))\n\n    ValueError: Input 0 is incompatible with layer forward_lstm_10: expected shape=(None, None, 31), found shape=(None, 5000, 30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzH4vfEdhw8K",
        "outputId": "f6b0adcf-0f0b-41b0-db4f-c7320d36fc0e"
      },
      "source": [
        "twt = ['Meetings: Because none of us is as dumb as all of us.']\n",
        "#vectorizing the tweet by the pre-fitted tokenizer instance\n",
        "twt = tokenizer.texts_to_sequences(twt)\n",
        "#padding the tweet to have exactly the same shape as `embedding_2` input\n",
        "twt = pad_sequences(twt, maxlen=40, dtype='int32', value=0)\n",
        "print(twt)\n",
        "sentiment = model.predict(twt,batch_size=1,verbose = 2)[0]\n",
        "if(np.argmax(sentiment) == 0):\n",
        "    print(\"negative\")\n",
        "elif (np.argmax(sentiment) == 1):\n",
        "    print(\"positive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0  204 1155   12  195    8   77 1628   77   33   12  195]]\n",
            "1/1 - 0s\n",
            "negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGqrv5wyjHmX"
      },
      "source": [
        "batch_size = 128\n",
        "modelBRNN.fit(X_train, y_train, epochs = 7, batch_size=batch_size, verbose = 2)\n",
        "print('BRNN Network accuracy test')\n",
        "score,acc = modelBRNN.evaluate(X_test, y_test, verbose = 2, batch_size = batch_size)\n",
        "modelBRNN.save('Brnn_simple.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NG1J5DhCCe2i"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Qs5GfGMGSsn"
      },
      "source": [
        "# Bert"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dmh3J421GWZ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "938f3284-208f-446c-b120-5ecd0bc3c181"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBj5MQmkGcA0"
      },
      "source": [
        "#necesita tensorflow 1.15 para correr\n",
        "!python3.7 -m pip install tensorflow-gpu==1.15.0\n",
        "from IPython.display import clear_output \n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9s8AUkvtGeVu"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLHezntZGg6Z"
      },
      "source": [
        "#texto a predecir\n",
        "text=\"I love mondays\"\n",
        "test_bert_df = pd.DataFrame({\n",
        "    'id': ['id',0],\n",
        "    'text': [\"text\",text]\n",
        "})\n",
        "test_bert_df.to_csv('data/test.tsv', sep='\\t', index=False, header=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJJ9eHWrJY7l"
      },
      "source": [
        "import run_classifier\n",
        "run_classifier(task_name==cola, )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06i8jlsMTNJ1",
        "outputId": "6b128874-be40-43cd-c797-6682604cecce"
      },
      "source": [
        "!python run_classifier.py --task_name=cola --do_predict=true --data_dir=./data/ --vocab_file=./uncased_L-12_H-768_A-12/vocab.txt --bert_config_file=./uncased_L-12_H-768_A-12/bert_config.json --init_checkpoint= drive/MyDrive/bert/model_output/model.ckpt-28125 --max_seq_length=128 --max_seq_length=128  --output_dir=./data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From run_classifier.py:981: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From run_classifier.py:784: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "W0422 03:17:44.376078 140581730781056 module_wrapper.py:139] From run_classifier.py:784: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "WARNING:tensorflow:From run_classifier.py:784: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "W0422 03:17:44.376317 140581730781056 module_wrapper.py:139] From run_classifier.py:784: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/bert/modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0422 03:17:44.376579 140581730781056 module_wrapper.py:139] From /content/drive/My Drive/bert/modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From run_classifier.py:808: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "W0422 03:17:44.378378 140581730781056 module_wrapper.py:139] From run_classifier.py:808: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "W0422 03:17:44.479429 140581730781056 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "I0422 03:17:45.020827 140581730781056 utils.py:157] NumExpr defaulting to 2 threads.\n",
            "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fdb44d8d8c0>) includes params argument, but params are not passed to Estimator.\n",
            "W0422 03:17:45.345788 140581730781056 estimator.py:1994] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fdb44d8d8c0>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Using config: {'_model_dir': './data', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fdb44e16e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': None}\n",
            "I0422 03:17:45.346651 140581730781056 estimator.py:212] Using config: {'_model_dir': './data', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fdb44e16e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': None}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "I0422 03:17:45.346914 140581730781056 tpu_context.py:220] _TPUContext: eval_on_tpu True\n",
            "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n",
            "W0422 03:17:45.347236 140581730781056 tpu_context.py:222] eval_on_tpu ignored because use_tpu is False.\n",
            "WARNING:tensorflow:From run_classifier.py:199: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0422 03:17:45.347526 140581730781056 module_wrapper.py:139] From run_classifier.py:199: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From run_classifier.py:483: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W0422 03:17:45.349551 140581730781056 module_wrapper.py:139] From run_classifier.py:483: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From run_classifier.py:487: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W0422 03:17:45.352775 140581730781056 module_wrapper.py:139] From run_classifier.py:487: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:Writing example 0 of 1\n",
            "I0422 03:17:45.352968 140581730781056 run_classifier.py:487] Writing example 0 of 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0422 03:17:45.353262 140581730781056 run_classifier.py:461] *** Example ***\n",
            "INFO:tensorflow:guid: test-1\n",
            "I0422 03:17:45.353396 140581730781056 run_classifier.py:462] guid: test-1\n",
            "INFO:tensorflow:tokens: [CLS] i love mondays [SEP]\n",
            "I0422 03:17:45.353496 140581730781056 run_classifier.py:464] tokens: [CLS] i love mondays [SEP]\n",
            "INFO:tensorflow:input_ids: 101 1045 2293 28401 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0422 03:17:45.353630 140581730781056 run_classifier.py:465] input_ids: 101 1045 2293 28401 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0422 03:17:45.353765 140581730781056 run_classifier.py:466] input_mask: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0422 03:17:45.353901 140581730781056 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "I0422 03:17:45.353983 140581730781056 run_classifier.py:468] label: 0 (id = 0)\n",
            "INFO:tensorflow:***** Running prediction*****\n",
            "I0422 03:17:45.355558 140581730781056 run_classifier.py:944] ***** Running prediction*****\n",
            "INFO:tensorflow:  Num examples = 1 (1 actual, 0 padding)\n",
            "I0422 03:17:45.356059 140581730781056 run_classifier.py:947]   Num examples = 1 (1 actual, 0 padding)\n",
            "INFO:tensorflow:  Batch size = 8\n",
            "I0422 03:17:45.356214 140581730781056 run_classifier.py:948]   Batch size = 8\n",
            "WARNING:tensorflow:From run_classifier.py:514: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "W0422 03:17:45.356423 140581730781056 module_wrapper.py:139] From run_classifier.py:514: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "INFO:tensorflow:***** Predict results *****\n",
            "I0422 03:17:45.356604 140581730781056 run_classifier.py:962] ***** Predict results *****\n",
            "INFO:tensorflow:Could not find trained model in model_dir: ./data, running initialization to predict.\n",
            "I0422 03:17:45.357142 140581730781056 estimator.py:615] Could not find trained model in model_dir: ./data, running initialization to predict.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "W0422 03:17:45.362310 140581730781056 deprecation.py:506] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From run_classifier.py:550: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch(...)`.\n",
            "W0422 03:17:45.377805 140581730781056 deprecation.py:323] From run_classifier.py:550: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch(...)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/data/python/ops/batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
            "W0422 03:17:45.378068 140581730781056 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/data/python/ops/batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "W0422 03:17:45.460039 140581730781056 module_wrapper.py:139] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "WARNING:tensorflow:From run_classifier.py:530: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0422 03:17:45.578938 140581730781056 deprecation.py:323] From run_classifier.py:530: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0422 03:17:45.593847 140581730781056 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Running infer on CPU\n",
            "I0422 03:17:45.594104 140581730781056 tpu_estimator.py:3124] Running infer on CPU\n",
            "INFO:tensorflow:*** Features ***\n",
            "I0422 03:17:45.594414 140581730781056 run_classifier.py:627] *** Features ***\n",
            "INFO:tensorflow:  name = input_ids, shape = (?, 128)\n",
            "I0422 03:17:45.594543 140581730781056 run_classifier.py:629]   name = input_ids, shape = (?, 128)\n",
            "INFO:tensorflow:  name = input_mask, shape = (?, 128)\n",
            "I0422 03:17:45.594642 140581730781056 run_classifier.py:629]   name = input_mask, shape = (?, 128)\n",
            "INFO:tensorflow:  name = is_real_example, shape = (?,)\n",
            "I0422 03:17:45.594718 140581730781056 run_classifier.py:629]   name = is_real_example, shape = (?,)\n",
            "INFO:tensorflow:  name = label_ids, shape = (?,)\n",
            "I0422 03:17:45.594789 140581730781056 run_classifier.py:629]   name = label_ids, shape = (?,)\n",
            "INFO:tensorflow:  name = segment_ids, shape = (?, 128)\n",
            "I0422 03:17:45.594863 140581730781056 run_classifier.py:629]   name = segment_ids, shape = (?, 128)\n",
            "WARNING:tensorflow:From /content/drive/My Drive/bert/modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0422 03:17:45.598354 140581730781056 module_wrapper.py:139] From /content/drive/My Drive/bert/modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/bert/modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "W0422 03:17:45.599783 140581730781056 module_wrapper.py:139] From /content/drive/My Drive/bert/modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/bert/modeling.py:490: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "W0422 03:17:45.632821 140581730781056 module_wrapper.py:139] From /content/drive/My Drive/bert/modeling.py:490: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/bert/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "W0422 03:17:45.687455 140581730781056 deprecation.py:323] From /content/drive/My Drive/bert/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0422 03:17:45.688287 140581730781056 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From run_classifier.py:647: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "W0422 03:17:47.546698 140581730781056 module_wrapper.py:139] From run_classifier.py:647: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "INFO:tensorflow:**** Trainable Variables ****\n",
            "I0422 03:17:47.546946 140581730781056 run_classifier.py:663] **** Trainable Variables ****\n",
            "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30522, 768)\n",
            "I0422 03:17:47.547049 140581730781056 run_classifier.py:669]   name = bert/embeddings/word_embeddings:0, shape = (30522, 768)\n",
            "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768)\n",
            "I0422 03:17:47.547164 140581730781056 run_classifier.py:669]   name = bert/embeddings/token_type_embeddings:0, shape = (2, 768)\n",
            "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768)\n",
            "I0422 03:17:47.547259 140581730781056 run_classifier.py:669]   name = bert/embeddings/position_embeddings:0, shape = (512, 768)\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,)\n",
            "I0422 03:17:47.547382 140581730781056 run_classifier.py:669]   name = bert/embeddings/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,)\n",
            "I0422 03:17:47.547486 140581730781056 run_classifier.py:669]   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0422 03:17:47.547571 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,)\n",
            "I0422 03:17:47.547667 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0422 03:17:47.547749 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,)\n",
            "I0422 03:17:47.547832 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0422 03:17:47.547912 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,)\n",
            "I0422 03:17:47.548005 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0422 03:17:47.548085 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,)\n",
            "I0422 03:17:47.548168 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0422 03:17:47.548246 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0422 03:17:47.548333 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0422 03:17:47.548417 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0422 03:17:47.548499 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0422 03:17:47.548588 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,)\n",
            "I0422 03:17:47.548672 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0422 03:17:47.548750 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0422 03:17:47.548835 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0422 03:17:47.548915 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,)\n",
            "I0422 03:17:47.549007 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0422 03:17:47.549086 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,)\n",
            "I0422 03:17:47.549165 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0422 03:17:47.549252 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,)\n",
            "I0422 03:17:47.549347 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0422 03:17:47.549432 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,)\n",
            "I0422 03:17:47.549512 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0422 03:17:47.549588 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0422 03:17:47.549663 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0422 03:17:47.549739 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0422 03:17:47.549823 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0422 03:17:47.549906 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,)\n",
            "I0422 03:17:47.550111 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0422 03:17:47.550193 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0422 03:17:47.550269 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0422 03:17:47.550378 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,)\n",
            "I0422 03:17:47.550477 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0422 03:17:47.550557 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,)\n",
            "I0422 03:17:47.550639 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0422 03:17:47.550718 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,)\n",
            "I0422 03:17:47.550799 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0422 03:17:47.550876 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,)\n",
            "I0422 03:17:47.550968 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0422 03:17:47.551046 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0422 03:17:47.551127 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0422 03:17:47.551209 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0422 03:17:47.551290 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0422 03:17:47.551389 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,)\n",
            "I0422 03:17:47.551472 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0422 03:17:47.551548 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0422 03:17:47.551624 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0422 03:17:47.551701 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,)\n",
            "I0422 03:17:47.551780 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0422 03:17:47.551857 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,)\n",
            "I0422 03:17:47.551944 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0422 03:17:47.552023 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,)\n",
            "I0422 03:17:47.552104 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0422 03:17:47.552181 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,)\n",
            "I0422 03:17:47.552261 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0422 03:17:47.552347 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0422 03:17:47.552431 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0422 03:17:47.552509 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0422 03:17:47.552589 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0422 03:17:47.552667 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,)\n",
            "I0422 03:17:47.552827 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0422 03:17:47.552906 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0422 03:17:47.552997 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0422 03:17:47.553076 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,)\n",
            "I0422 03:17:47.553157 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0422 03:17:47.553235 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,)\n",
            "I0422 03:17:47.553329 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0422 03:17:47.553416 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,)\n",
            "I0422 03:17:47.553499 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0422 03:17:47.553582 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,)\n",
            "I0422 03:17:47.553663 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0422 03:17:47.553743 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0422 03:17:47.615859 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0422 03:17:47.616145 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0422 03:17:47.616374 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0422 03:17:47.616564 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,)\n",
            "I0422 03:17:47.616762 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0422 03:17:47.616922 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0422 03:17:47.617053 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0422 03:17:47.617186 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,)\n",
            "I0422 03:17:47.617337 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0422 03:17:47.617477 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,)\n",
            "I0422 03:17:47.617623 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0422 03:17:47.617759 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,)\n",
            "I0422 03:17:47.617894 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0422 03:17:47.618036 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,)\n",
            "I0422 03:17:47.618171 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0422 03:17:47.618299 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0422 03:17:47.619587 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0422 03:17:47.619759 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0422 03:17:47.619919 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0422 03:17:47.620058 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,)\n",
            "I0422 03:17:47.620230 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0422 03:17:47.620399 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0422 03:17:47.620549 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0422 03:17:47.620650 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,)\n",
            "I0422 03:17:47.620740 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0422 03:17:47.620825 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,)\n",
            "I0422 03:17:47.620929 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0422 03:17:47.621011 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,)\n",
            "I0422 03:17:47.621112 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0422 03:17:47.621199 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,)\n",
            "I0422 03:17:47.621283 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0422 03:17:47.621375 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0422 03:17:47.621453 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0422 03:17:47.621531 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0422 03:17:47.621612 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0422 03:17:47.621691 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,)\n",
            "I0422 03:17:47.621772 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0422 03:17:47.621849 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0422 03:17:47.621924 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0422 03:17:47.622000 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,)\n",
            "I0422 03:17:47.622079 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0422 03:17:47.622165 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,)\n",
            "I0422 03:17:47.622245 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0422 03:17:47.622336 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,)\n",
            "I0422 03:17:47.622420 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0422 03:17:47.622499 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,)\n",
            "I0422 03:17:47.622580 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0422 03:17:47.622665 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0422 03:17:47.622753 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0422 03:17:47.622834 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0422 03:17:47.622915 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0422 03:17:47.622997 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,)\n",
            "I0422 03:17:47.623078 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0422 03:17:47.623165 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0422 03:17:47.623240 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0422 03:17:47.623317 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,)\n",
            "I0422 03:17:47.623420 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0422 03:17:47.623498 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,)\n",
            "I0422 03:17:47.623589 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0422 03:17:47.623667 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,)\n",
            "I0422 03:17:47.623746 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0422 03:17:47.623827 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,)\n",
            "I0422 03:17:47.623907 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0422 03:17:47.623983 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0422 03:17:47.624058 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0422 03:17:47.624144 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0422 03:17:47.624224 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0422 03:17:47.624302 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,)\n",
            "I0422 03:17:47.624392 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0422 03:17:47.624468 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0422 03:17:47.624543 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0422 03:17:47.624620 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,)\n",
            "I0422 03:17:47.624700 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0422 03:17:47.624782 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,)\n",
            "I0422 03:17:47.624868 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0422 03:17:47.624947 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,)\n",
            "I0422 03:17:47.625028 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0422 03:17:47.625114 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,)\n",
            "I0422 03:17:47.625197 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0422 03:17:47.625273 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0422 03:17:47.625373 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0422 03:17:47.625454 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0422 03:17:47.717790 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0422 03:17:47.718035 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,)\n",
            "I0422 03:17:47.718338 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0422 03:17:47.718494 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0422 03:17:47.718641 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0422 03:17:47.718774 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,)\n",
            "I0422 03:17:47.718922 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0422 03:17:47.719054 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,)\n",
            "I0422 03:17:47.719197 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0422 03:17:47.719344 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,)\n",
            "I0422 03:17:47.719476 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0422 03:17:47.719608 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,)\n",
            "I0422 03:17:47.719740 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0422 03:17:47.719869 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0422 03:17:47.719999 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0422 03:17:47.720132 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0422 03:17:47.720268 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0422 03:17:47.720409 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,)\n",
            "I0422 03:17:47.720546 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0422 03:17:47.720684 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0422 03:17:47.720811 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0422 03:17:47.720960 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,)\n",
            "I0422 03:17:47.721099 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0422 03:17:47.721226 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,)\n",
            "I0422 03:17:47.721368 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0422 03:17:47.721495 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,)\n",
            "I0422 03:17:47.721626 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0422 03:17:47.721791 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,)\n",
            "I0422 03:17:47.721919 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0422 03:17:47.722045 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0422 03:17:47.722173 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0422 03:17:47.722298 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0422 03:17:47.722445 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0422 03:17:47.722570 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,)\n",
            "I0422 03:17:47.722700 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0422 03:17:47.722829 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0422 03:17:47.722956 140581730781056 run_classifier.py:669]   name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768)\n",
            "I0422 03:17:47.723088 140581730781056 run_classifier.py:669]   name = bert/pooler/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,)\n",
            "I0422 03:17:47.723219 140581730781056 run_classifier.py:669]   name = bert/pooler/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = output_weights:0, shape = (2, 768)\n",
            "I0422 03:17:47.723360 140581730781056 run_classifier.py:669]   name = output_weights:0, shape = (2, 768)\n",
            "INFO:tensorflow:  name = output_bias:0, shape = (2,)\n",
            "I0422 03:17:47.723490 140581730781056 run_classifier.py:669]   name = output_bias:0, shape = (2,)\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0422 03:17:47.723939 140581730781056 estimator.py:1150] Done calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0422 03:17:47.872499 140581730781056 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0422 03:17:48.207885 140581730781056 monitored_session.py:240] Graph was finalized.\n",
            "2021-04-22 03:17:48.208473: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
            "2021-04-22 03:17:48.213984: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1999995000 Hz\n",
            "2021-04-22 03:17:48.214235: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55cc53a76f40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-04-22 03:17:48.214270: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-04-22 03:17:48.216181: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2021-04-22 03:17:48.228208: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2021-04-22 03:17:48.228256: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (f2e236daf10d): /proc/driver/nvidia/version does not exist\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0422 03:17:51.045973 140581730781056 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0422 03:17:51.091497 140581730781056 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "I0422 03:17:52.101597 140581730781056 error_handling.py:101] prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "I0422 03:17:52.101861 140581730781056 error_handling.py:101] prediction_loop marked as finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHrSV-7DGjFz"
      },
      "source": [
        "#result \n",
        "df=pd.read_csv('data/test_results.tsv', sep='\\t')\n",
        "results=(df.columns[0],df.columns[1])\n",
        "print(text)\n",
        "print(\"probablility of text being negative: \", results[0],' probablility of text being positive:', results[1] )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ft94r7exyZKR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Leh0smfUyZnI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrHTgk_ugNxQ"
      },
      "source": [
        "# GRU \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcAViPaJyaUa",
        "outputId": "7f43cec8-58f1-4373-831e-f05fc50b87e8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXoyo39CXqg2"
      },
      "source": [
        "import pandas as pd\n",
        "train=pd.read_csv('/content/drive/MyDrive/Datasets/data_trainsinlinks.csv')\n",
        "test=pd.read_csv('/content/drive/MyDrive/Datasets/data_testsinlinks.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AU7JNWwHXqkM"
      },
      "source": [
        "x_train=train.text.to_numpy()\n",
        "y_train=train.label.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueyDV8XHXqnO"
      },
      "source": [
        "\n",
        "x_test=test.text.to_numpy()\n",
        "y_test=test.label.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwbVp-dqXqqV",
        "outputId": "18efd55b-315e-4a98-f57f-90d683e18738"
      },
      "source": [
        "VOCAB_SIZE = 1000\n",
        "encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
        "    max_tokens=VOCAB_SIZE)\n",
        "encoder.adapt(x_train)\n",
        "vocab = np.array(encoder.get_vocabulary())\n",
        "vocab[:20]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['', '[UNK]', 'i', 'to', 'the', 'a', 'my', 'and', 'you', 'is', 'it',\n",
              "       'for', 'in', 'of', 'im', 'on', 'me', 'so', 'have', 'that'],\n",
              "      dtype='<U13')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbeUjN8EYet8"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    encoder,\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim=len(encoder.get_vocabulary()),\n",
        "        output_dim=64,\n",
        "        # Use masking to handle the variable sequence lengths\n",
        "        mask_zero=True),\n",
        "    tf.keras.layers.GRU(4),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(64),\n",
        "    tf.keras.layers.Dense(1,activation='sigmoid')\n",
        "])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9o4hF5NpYezp"
      },
      "source": [
        "model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovjDG-QmYoem",
        "outputId": "b0fe2cde-5b34-4739-d207-208ddc00fd55"
      },
      "source": [
        "history = model.fit(x=x_train, y=y_train, epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "37500/37500 [==============================] - 2934s 78ms/step - loss: 0.1785 - accuracy: 0.7330\n",
            "Epoch 2/5\n",
            "37500/37500 [==============================] - 2945s 79ms/step - loss: 0.1604 - accuracy: 0.7708\n",
            "Epoch 3/5\n",
            "37500/37500 [==============================] - 2944s 79ms/step - loss: 0.1573 - accuracy: 0.7746\n",
            "Epoch 4/5\n",
            "37500/37500 [==============================] - 2936s 78ms/step - loss: 0.1550 - accuracy: 0.7790\n",
            "Epoch 5/5\n",
            "37500/37500 [==============================] - 2938s 78ms/step - loss: 0.1531 - accuracy: 0.7817\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "EJTxSolPYoiL",
        "outputId": "1d93e54f-0872-4969-d586-49f89f38da74"
      },
      "source": [
        "model.save('drive/MyDrive/rnn_Gru')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-29599d36454d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'drive/MyDrive/rnn_Gru'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_A7cBNHgLwd",
        "outputId": "50bc4f9b-cbc6-428f-a7d5-c7074a723348"
      },
      "source": [
        "import keras\n",
        "#run predict\n",
        "text='i like mondays'\n",
        "modelGRU=keras.models.load_model('rnn_Gru')\n",
        "prediction=modelGRU.predict(np.array([text]))\n",
        "print(prediction)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.7136958]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhCEWvuJVG-9"
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "# compile the model\n",
        "modelGRU.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc',f1_m,precision_m, recall_m])\n",
        "\n",
        "# fit the model\n",
        "#history = modelbi.fit(x_train, y_train, validation_split=0.3, epochs=1, verbose=0)\n",
        "\n",
        "# evaluate the model\n",
        "loss, accuracy, f1_score, precision, recall = modelGRU.evaluate(x_test, y_test, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4vciZdgXQln",
        "outputId": "d452c404-918b-4974-ee09-2d7aa2b5731a"
      },
      "source": [
        "print('LOSS',loss,'accuracy',accuracy,'precision',precision,'recall',recall)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LOSS 0.45887577533721924 accuracy 0.7851974964141846 precision 0.7771639823913574 recall 0.7987796664237976\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SF7NobaWA8Ra"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpuF5boRBHkX"
      },
      "source": [
        "# Rnns validation\n",
        "\n",
        "\n",
        "---\n",
        "#the training was lost (colab didnt saved it) but we have the models saved\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEewkXO5DMee"
      },
      "source": [
        " #BIDIRECTIONAL\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VroHZfBCBHka",
        "outputId": "c5fc2bb9-d945-41ca-861c-e83cd69968d9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXCXehVIBHkb"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdAMQn9jBHkb",
        "outputId": "975a025e-22cb-40e0-840a-fcdcd5cb8f6f"
      },
      "source": [
        "#run predict rnn_bi\n",
        "text='i like mondays'\n",
        "modelbi=tf.keras.models.load_model('rnn_bi')\n",
        "prediction=model.predict(np.array([text]))\n",
        "print(prediction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.7696788]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xr58GWjDBHkc",
        "outputId": "7258a781-ddad-4251-ad51-aabeae081a8d"
      },
      "source": [
        "modelbi=keras.models.load_model('rnn_bi')\n",
        "#print(\"RNN accuracy percent:\",nltk.classify.accuracy(modelbi, testing_set)*100)\n",
        "print(modelbi.evaluate(x_train,y_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "36564/37500 [============================>.] - ETA: 14s - loss: 0.4117 - accuracy: 0.8071"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptPJpdRYDedE"
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "# compile the model\n",
        "modelbi.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc',f1_m,precision_m, recall_m])\n",
        "\n",
        "# fit the model\n",
        "#history = modelbi.fit(x_train, y_train, validation_split=0.3, epochs=1, verbose=0)\n",
        "\n",
        "# evaluate the model\n",
        "loss, accuracy, f1_score, precision, recall = modelbi.evaluate(x_test, y_test, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAKz5-CED0sX",
        "outputId": "179ccd3d-e025-4657-a9a9-446923180ab2"
      },
      "source": [
        "print('LOSS',loss,'accuracy',accuracy,'precision',precision,'recall',recall)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LOSS 0.42626750469207764 accuracy 0.7991474866867065 precision 0.8080272078514099 recall 0.7843748927116394\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjvF-mccDXw_"
      },
      "source": [
        " #LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdMw3KBiBHkc",
        "outputId": "85b1e00c-2145-408b-9b5e-9cd15611064f"
      },
      "source": [
        "#run predict rnn_lstm how positive the text is\n",
        "text='i hate mondays'\n",
        "modellstm=tf.keras.models.load_model('rnn_lstm')\n",
        "prediction=model.predict(np.array([text]))\n",
        "print(prediction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x7f075ff11710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[[0.02012162]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyqhNq4YBHkd"
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "# compile the model\n",
        "modellstm.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc',f1_m,precision_m, recall_m])\n",
        "\n",
        "# fit the model\n",
        "#history = modelbi.fit(x_train, y_train, validation_split=0.3, epochs=1, verbose=0)\n",
        "\n",
        "# evaluate the model\n",
        "loss, accuracy, f1_score, precision, recall = modellstm.evaluate(x_test, y_test, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9D8O9p7PA8Uf",
        "outputId": "59989fe3-8a33-45fd-f973-93427236da73"
      },
      "source": [
        "print('LOSS',loss,'accuracy',accuracy,'precision',precision,'recall',recall)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LOSS 0.42681652307510376 accuracy 0.7985175251960754 precision 0.7927082777023315 recall 0.808042585849762\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhpFtI3oA8XH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prLlyW_DevRV"
      },
      "source": [
        "# STREAMLIT\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WyI-fMGre1Sx",
        "outputId": "f05fe472-5af7-4165-9dd7-d3f3b331e84f"
      },
      "source": [
        "!pip install streamlit"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting streamlit\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/99/a8913c21bd07a14f72658a01784414ffecb380ddd0f9a127257314fea697/streamlit-0.80.0-py2.py3-none-any.whl (8.2MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2MB 7.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.8.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from streamlit) (0.10.2)\n",
            "Collecting base58\n",
            "  Downloading https://files.pythonhosted.org/packages/b8/a1/d9f565e9910c09fd325dc638765e8843a19fa696275c16cc08cf3b0a3c25/base58-2.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.23.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (7.1.2)\n",
            "Collecting pydeck>=0.1.dev5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/bc/f0e44828e4290367c869591d50d3671a4d0ee94926da6cb734b7b200308c/pydeck-0.6.2-py2.py3-none-any.whl (4.2MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2MB 50.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf!=3.11,>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (3.12.4)\n",
            "Requirement already satisfied: altair>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (4.1.0)\n",
            "Requirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (5.1.1)\n",
            "Requirement already satisfied: pandas>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.1.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from streamlit) (20.9)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.5.1)\n",
            "Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (4.2.1)\n",
            "Requirement already satisfied: pyarrow; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from streamlit) (3.0.0)\n",
            "Collecting validators\n",
            "  Downloading https://files.pythonhosted.org/packages/db/2f/7fed3ee94ad665ad2c1de87f858f10a7785251ff75b4fd47987888d07ef1/validators-0.18.2-py3-none-any.whl\n",
            "Collecting gitpython\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/99/98019716955ba243657daedd1de8f3a88ca1f5b75057c38e959db22fb87b/GitPython-3.1.14-py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 56.9MB/s \n",
            "\u001b[?25hCollecting watchdog; platform_system != \"Darwin\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/b2/b4ebe23174fd00ec94ac3f58ebf85f1090c49858feab1ca62ed7ea4d2f2f/watchdog-2.0.3-py3-none-manylinux2014_x86_64.whl (74kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 12.5MB/s \n",
            "\u001b[?25hCollecting blinker\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/51/e2a9f3b757eb802f61dc1f2b09c8c99f6eb01cf06416c0671253536517b6/blinker-1.4.tar.gz (111kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 43.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.19.5)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from streamlit) (0.8.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (7.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->streamlit) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (2.10)\n",
            "Requirement already satisfied: ipywidgets>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit) (7.6.3)\n",
            "Collecting ipykernel>=5.1.2; python_version >= \"3.4\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/7d/9f8ac1b1b76f2f1538b5650f0b5636bae082724b1e06939a3a9d38e1380e/ipykernel-5.5.3-py3-none-any.whl (120kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 54.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit) (2.11.3)\n",
            "Requirement already satisfied: traitlets>=4.3.2 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit) (5.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf!=3.11,>=3.6.0->streamlit) (56.0.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (2.6.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (0.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (0.11.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.0->streamlit) (2018.9)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->streamlit) (2.4.7)\n",
            "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from validators->streamlit) (4.4.2)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 11.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.0.0)\n",
            "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.5.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.1.3)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (3.5.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (5.3.5)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.10.1->pydeck>=0.1.dev5->streamlit) (1.1.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.3.2->pydeck>=0.1.dev5->streamlit) (0.2.0)\n",
            "Collecting smmap<5,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.7.5)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.8.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (2.6.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (4.7.1)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.3.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (22.0.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.7.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.6.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.9.4)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.5.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.4.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.4.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.7.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.8.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (3.3.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.5.1)\n",
            "Building wheels for collected packages: blinker\n",
            "  Building wheel for blinker (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for blinker: filename=blinker-1.4-cp37-none-any.whl size=13448 sha256=f91ad80a6b2c987ed3bdf00cd95970530262a7a5f822785e5db5da631861e7d4\n",
            "  Stored in directory: /root/.cache/pip/wheels/92/a0/00/8690a57883956a301d91cf4ec999cc0b258b01e3f548f86e89\n",
            "Successfully built blinker\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement ipykernel~=4.10, but you'll have ipykernel 5.5.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: base58, ipykernel, pydeck, validators, smmap, gitdb, gitpython, watchdog, blinker, streamlit\n",
            "  Found existing installation: ipykernel 4.10.1\n",
            "    Uninstalling ipykernel-4.10.1:\n",
            "      Successfully uninstalled ipykernel-4.10.1\n",
            "Successfully installed base58-2.1.0 blinker-1.4 gitdb-4.0.7 gitpython-3.1.14 ipykernel-5.5.3 pydeck-0.6.2 smmap-4.0.0 streamlit-0.80.0 validators-0.18.2 watchdog-2.0.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "ipykernel"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYBU6TENMSoN",
        "outputId": "ffecd85f-a669-46f8-cfc3-928b15e5e0d2"
      },
      "source": [
        "!pip install pyngrok"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyngrok\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6b/4e/a2fe095bbe17cf26424c4abcd22a0490e22d01cc628f25af5e220ddbf6f0/pyngrok-5.0.5.tar.gz (745kB)\n",
            "\u001b[K     |████████████████████████████████| 747kB 9.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyngrok) (3.13)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-5.0.5-cp37-none-any.whl size=19246 sha256=9dfb720d0999f91136cd2ecccce3446745b73f06aef10c8048d093ca0ba5317e\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/13/64/5ebbcc22eaf53fdf5766b397c1fb17c83f5775fdccf0ea1b88\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-5.0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YBC7us2fydr",
        "outputId": "de42839d-f4ed-488b-c3e9-65d6a3651ab1"
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-28 00:54:20--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 54.235.211.105, 34.202.43.88, 52.200.34.95, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|54.235.211.105|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13828408 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.19M  16.1MB/s    in 0.8s    \n",
            "\n",
            "2021-04-28 00:54:21 (16.1 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13828408/13828408]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "op2L9bztfzPR",
        "outputId": "562a6aaf-3301-4afc-c405-bf9127f19d85"
      },
      "source": [
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuWNC15wfzVF",
        "outputId": "b9d465f8-5e93-47ab-e2a3-9a8fab792236"
      },
      "source": [
        "!ngrok"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NAME:\n",
            "   ngrok - tunnel local ports to public URLs and inspect traffic\n",
            "\n",
            "DESCRIPTION:\n",
            "    ngrok exposes local networked services behinds NATs and firewalls to the\n",
            "    public internet over a secure tunnel. Share local websites, build/test\n",
            "    webhook consumers and self-host personal services.\n",
            "    Detailed help for each command is available with 'ngrok help <command>'.\n",
            "    Open http://localhost:4040 for ngrok's web interface to inspect traffic.\n",
            "\n",
            "EXAMPLES:\n",
            "    ngrok http 80                    # secure public URL for port 80 web server\n",
            "    ngrok http -subdomain=baz 8080   # port 8080 available at baz.ngrok.io\n",
            "    ngrok http foo.dev:80            # tunnel to host:port instead of localhost\n",
            "    ngrok http https://localhost     # expose a local https server\n",
            "    ngrok tcp 22                     # tunnel arbitrary TCP traffic to port 22\n",
            "    ngrok tls -hostname=foo.com 443  # TLS traffic for foo.com to port 443\n",
            "    ngrok start foo bar baz          # start tunnels from the configuration file\n",
            "\n",
            "VERSION:\n",
            "   2.3.39\n",
            "\n",
            "AUTHOR:\n",
            "  inconshreveable - <alan@ngrok.com>\n",
            "\n",
            "COMMANDS:\n",
            "   authtoken\tsave authtoken to configuration file\n",
            "   credits\tprints author and licensing information\n",
            "   http\t\tstart an HTTP tunnel\n",
            "   start\tstart tunnels by name from the configuration file\n",
            "   tcp\t\tstart a TCP tunnel\n",
            "   tls\t\tstart a TLS tunnel\n",
            "   update\tupdate ngrok to the latest version\n",
            "   version\tprint the version string\n",
            "   help\t\tShows a list of commands or help for one command\n",
            "\n",
            "PYNGROK VERSION:\n",
            "   5.0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B15houXtfzZw",
        "outputId": "a27c37ce-9f2d-48f1-97f1-50b56cc0d2fc"
      },
      "source": [
        "\n",
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import tweepy\n",
        "from tweepy import Stream\n",
        "from tweepy import OAuthHandler\n",
        "from tweepy.streaming import StreamListener\n",
        "import time\n",
        "import json\n",
        "import sentiment_mod as s\n",
        "import praw\n",
        "import re\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import streamlit as st\n",
        "\n",
        "import numpy as np\n",
        "import pickle\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "#from xgboost import XGBRegressor\n",
        "\n",
        "\n",
        "st.set_page_config(\n",
        "\tpage_title=\"Ex-stream-ly Cool App\",\n",
        "\tpage_icon=\"\",\n",
        "\tlayout=\"wide\",\n",
        "\tinitial_sidebar_state=\"auto\",\n",
        ")\n",
        "\n",
        "\n",
        "page_bg_img = '''\n",
        "<style>\n",
        "body {\n",
        "background-image: url(\"https://images.unsplash.com/photo-1454117096348-e4abbeba002c?ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&ixlib=rb-1.2.1&auto=format&fit=crop&w=1350&q=80\");\n",
        "background-size: cover;\n",
        "}\n",
        "</style>\n",
        "'''\n",
        "\n",
        "st.markdown(page_bg_img, unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "st.markdown(\n",
        "\t'''\n",
        "\t\t<style>\n",
        "\t\t\t.sidebar.sidebar-content {{\n",
        "\t\t\t\twidth: 20px;\n",
        "\t\t\t}}\n",
        "\t\t</style>\n",
        "\t''',\n",
        "\tunsafe_allow_html=True\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "html_temp = \"\"\"\n",
        "<div style=\"background-color:black;padding:10px\">\n",
        "<h1 style=\"color:white;text-align:center;\">SENTIMENT ANALYZER </h1>\n",
        "</div>\n",
        "\"\"\"\n",
        "\n",
        "st.markdown(html_temp,unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "st.sidebar.header('Choose Social Media')\n",
        "\n",
        "\n",
        "add_selectbox = st.sidebar.selectbox(\"What would you want to predict\", (\"Create sentence\",\"Twitter\", \"Reddit\"))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "st.subheader('Single tweet classification')\n",
        "\n",
        "# USAR ESTO PARA PREDICCIONES \n",
        "#tweet_input = st.text_input('Tweet:')\n",
        "\n",
        "#consumer key, consumer secret, access token, access secret.\n",
        "ckey=\n",
        "csecret=\n",
        "atoken=\n",
        "asecret=\"\n",
        "\n",
        "\n",
        "\n",
        "auth = OAuthHandler(ckey, csecret)\n",
        "auth.set_access_token(atoken, asecret)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if add_selectbox == \"Create sentence\":\n",
        "\n",
        "#run predict rnn_lstm how positive the text is\n",
        "  text=st.text_input(\"Enter a sentence\")\n",
        "  \n",
        "  #print(prediction)\n",
        "  st.sidebar.header('Select a Recurrent Neural Network for prediction')\n",
        " \n",
        "  if st.sidebar.button('predict LSTM '):\n",
        "    modellstm=tf.keras.models.load_model('rnn_lstm')\n",
        "    prediction=modellstm.predict(np.array([text]))\n",
        "\n",
        "    #st.write(prediction)\n",
        "    st.write('Positive confidence:', prediction)\n",
        "  else :\n",
        "    if st.sidebar.button('predict Bidirectional '):\n",
        "      modelbi=tf.keras.models.load_model('rnn_bi')\n",
        "      prediction=modelbi.predict(np.array([text]))\n",
        "\n",
        "      st.write('Positive confidence:',prediction)\n",
        "  if st.sidebar.button('predict GRU '):\n",
        "      modelGRU=tf.keras.models.load_model('rnn_Gru')\n",
        "      prediction=modelGRU.predict(np.array([text]))\n",
        "\n",
        "      st.write('Positive confidence:', prediction)\n",
        "\n",
        "\n",
        " \n",
        "else :\n",
        " if add_selectbox == \"Twitter\":\n",
        "\n",
        "  user=st.text_input(\"Enter Twitter username:\")\n",
        "\n",
        "  def get_twitter_client():\n",
        "  \n",
        "    client=tweepy.API(auth,wait_on_rate_limit=True)\n",
        "    return client\n",
        "\n",
        "\n",
        "  client=get_twitter_client()\n",
        "  for status in tweepy.Cursor(client.user_timeline,screen_name=user).items(10):\n",
        "    st.write(status.text,s.sentiment(status.text))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if add_selectbox==\"Reddit\": \n",
        "      reddit = praw.Reddit(\n",
        "      client_id=\"ebQ6RrLYWl4Q2Q\",\n",
        "      client_secret=\"IPMelkpgU8VtV-k70S9LqFS_99lmPw\",\n",
        "      user_agent=\"jupyter:1:1 (by /u/allicnam)\",\n",
        "      )\n",
        "\n",
        "      user=st.text_input(\"Enter Reddit username(try thisisbillgates):\")\n",
        "    #funcion que regresa un reditor dado el nombre de un usuario\n",
        "      def getRedditor(user):\n",
        "        return reddit.redditor(user)\n",
        "\n",
        "      #funcion que busca en los posts de un usuario y preprocesa el texto\n",
        "      def searchByRedditor(user, limit):\n",
        "        redditor = getRedditor(user)\n",
        "     \n",
        "        posts = []\n",
        "    \n",
        "        for submission in reddit.redditor(user).submissions.new(limit=limit):\n",
        "        #eliminar hyperlinks\n",
        "         processedtext = re.sub(r'\\[(?P<word>.*?)\\].*?\\)', '\\g<word>', submission.selftext)\n",
        "        #eliminar subbreddits (r/...)\n",
        "         processedtext = re.sub(r'r\\/(?P<subr>\\w*)', '\\g<subr>', processedtext)\n",
        "        #eliminar usuarios (u/...)\n",
        "         processedtext = re.sub(r'u\\/(?P<subr>\\w*)', '', processedtext)\n",
        "         posts.append(processedtext)\n",
        "    \n",
        "        return posts\n",
        "\n",
        "    #ejemplo\n",
        "      st.write(searchByRedditor(user,5)[4],s.sentiment(searchByRedditor(user,5)[4]))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBEue9uHfzeb",
        "outputId": "e10cd807-ef56-400a-ed02-d9dee74164c7"
      },
      "source": [
        "!streamlit run --server.port 80 app.py >/dev/null"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-28 03:59:04.830 An update to the [server] config option section was detected. To have these changes be reflected, please restart streamlit.\n",
            "2021-04-28 03:59:10.663147: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeoQGMR7gZNV",
        "outputId": "e6164e9a-d337-4aed-f10c-9dab202336e2"
      },
      "source": [
        "from pyngrok import ngrok\n",
        "# Setup a tunnel to the streamlit port 8501\n",
        "public_url = ngrok.connect(port='80')\n",
        "public_url"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<NgrokTunnel: \"http://e7ec9646bf31.ngrok.io\" -> \"http://localhost:80\">"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 305
        }
      ]
    }
  ]
}